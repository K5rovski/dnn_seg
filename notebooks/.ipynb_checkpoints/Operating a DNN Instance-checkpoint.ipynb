{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operating DNN Pixel Classifier Model\n",
    "\n",
    "\n",
    "This module is about training/testing a deep neural network, using a basic architecture of a pixel classifier ( originally proposed by <sup>   [[ciresan2012]](http://people.idsia.ch/~ciresan/data/nips2012.pdf)</sup>).\n",
    "\n",
    "+ The specific neural network model used, is defined elsewhere (`net/utils/models.py`).\n",
    "\n",
    "\n",
    "\n",
    "![DNN Model](https://i.imgur.com/hC3AL1b.png)\n",
    "This image gives an overview of the basic architecture.\n",
    "\n",
    "#### Basically the NN is constructed from densifying pyramidal blocks of (conv-relu; maxpool) NN layers.\n",
    "\n",
    "#### The first layer can have **copied weights**, taken from a previously trained AEN model.\n",
    "\n",
    "\n",
    "Using this notebook, a DNN model can be:\n",
    " 1. Trained from a lmdb training database, with specific train parameters;\n",
    " 2. Tested using a full **interim** image set input, to generate _\"cleared\"_ **DNN Corrected** representations.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViHv0jwqwhTk"
   },
   "source": [
    "# Importing modules\n",
    "\n",
    "Importing all dependent python functions for training a DNN.\n",
    "\n",
    "The main computational frameworks used were:\n",
    "+ [Keras](https://keras.io/) as a high level DNN Python API.\n",
    "+ [Tensorflow](https://www.tensorflow.org/) as a low level GPU processing framework.\n",
    "\n",
    "Additionally [LMDB](https://lmdb.readthedocs.io/) was used as a database API for data managment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jsP-NmUZwhTl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every import is succesful !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from numpy import array as arr\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard,EarlyStopping,LambdaCallback\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dnn_segmentation.net.utils as net_utils\n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.train_h import iterate_indef\n",
    " \n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.train_h import \\\n",
    "    quick_test,get_session,draw_onfirst_epoch,save_relevant,\\\n",
    "    use_best_model,use_num_model\n",
    "\n",
    "from dnn_segmentation.net.utils.models import \\\n",
    "    get_2k_image_good_convmodel,get_2k_twopath_simple,\\\n",
    "    get_2k_twopath_twoconv,get_2k_image_pretrained, \\\n",
    "    get_2k_image_2layer_convnetmodel\n",
    "    \n",
    "print('Every import is succesful !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5v2IYIGwhTp"
   },
   "source": [
    "## Setting training/testing parameters\n",
    "\n",
    "Here all training/testing parameters before processing are set.\n",
    "\n",
    "Mainly they can be divided in:\n",
    "1. Boolean Configuration Flag  \n",
    "\n",
    "   + Train a **New** DNN Model, \n",
    "    \n",
    "   + **Predict** with an existing model to _\"correct\"_ a full image set.\n",
    "    \n",
    "1. Model, Data **path locations**;\n",
    "2. Input image/patch info;\n",
    "3. DNN training info\n",
    "    1. optimiser\n",
    "    2. batch size\n",
    "    3. num of train epochs\n",
    "4. Other programatical processing flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "68WCLUoTwhTq"
   },
   "outputs": [],
   "source": [
    "# DNN Main Processing FLAG\n",
    "newTrain=False\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(None)\n",
    "KTF.set_session(get_session(0.8))\n",
    "\n",
    "\n",
    "model_locs=r'../test_data'\n",
    "log_loc=r'../test_data/logs'  # Not used, tensorflow log location\n",
    "\n",
    "\n",
    "val_lmdb=r'######/val_db'\n",
    "train_lmdb=r'####/train_db'\n",
    "\n",
    "img_w,img_h=45,45\n",
    "big_img_size=2048\n",
    "\n",
    "# optimizer = SGD(lr=0.0001, decay=0.0005, \n",
    "# momentum=0.9, nesterov=True)\n",
    "optimizer='adadelta'\n",
    "\n",
    "loss_func='categorical_crossentropy' \n",
    "\n",
    "batch_size=500\n",
    "epoch_count=3\n",
    "\n",
    "\n",
    "#  Random short nametag, for every new model experiment.\n",
    "quick_str=''.join(map(chr,np.random.randint(97,97+26,(4,))) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "split_patches=True  # true for autoenc\n",
    "\n",
    "single_map_autoenc=False #true for single autoenc\n",
    "numchannel_autoenc=3 # true for..1\n",
    "\n",
    "\n",
    "epoch_toDraw=None # None for best epoch\n",
    "start_patch48=True  # true for autoenc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kL-p-aIwhTt"
   },
   "source": [
    "## Aditional setup parameters\n",
    "\n",
    "* Setting **pretraining** parameters\n",
    " 1. Crbm based pretraining\n",
    " 2. Autoenc based pretraining\n",
    "* Setting validation frequency\n",
    "* Other flags\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "noJGNmVHwhTu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model is:  weights_data_vjat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "added_stuff={\n",
    "            # 'path_pretrain':\n",
    "            #      r'crmb_model_valloss_3333.npy',\n",
    "    'use_crbm':False,\n",
    "    'use_autoenc':True,\n",
    "             'autoenc_loc':r'../test_data/weights_autoenc_gced.00-0.1958.hdf5',\n",
    "             'autoenc_layer':'convolution2d_1'}\n",
    "\n",
    "train_autoenc_loc=r'../test_data/autoenc_train'\n",
    "reduce_valSize_Fac=0.2 # 1\n",
    "\n",
    "do_quick_after_train=False\n",
    "do_test_after_one=False\n",
    "test_after_train_fullset=False\n",
    "\n",
    "\n",
    "do_whole_pic=True\n",
    "draw_img_ext='*.tif'\n",
    "val_freq=122300\n",
    "\n",
    "\n",
    "weights_prepend='weights_data_'+quick_str\n",
    "\n",
    "\n",
    "print('New Model is: ',weights_prepend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RlP3YotwhTw"
   },
   "source": [
    "## DNN Correcting Images\n",
    "\n",
    "\n",
    "### (skip if new DNN training) \n",
    "\n",
    "This codeblock is for _\"testing\"_ a previously trained DNN module.\n",
    "\n",
    "\n",
    "For start, some configurtation parameters:\n",
    "+ Location path of data, image sets;\n",
    "+ Correcting DNN model location;\n",
    "+ Correcting experiment tag;\n",
    "+ Image set iterator\n",
    "\n",
    "With the configuration, \n",
    "\n",
    "the code iteratively uses the DNN to _\"clean\"_ the input **interim** patches, (subset from the full EM **preprocessed** images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tqP68ibgwhTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continued Training\n",
      "['../test_data/possible_dnn_input/sp13726-img05-interim.tif'] 0 1 ../test_data/possible_dnn_input\n",
      "Drawing on these:  1 ['../test_data/possible_dnn_input/sp13726-img05-interim.tif']\n",
      "Testing started - 3.498679\n",
      "Running on img:sp13726-img05-interim.tif\n",
      "Starting patching on image:  sp13726-img05  ...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b80d445441ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                    \u001b[0msplit_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_patches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                    \u001b[0mconf_dikt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_parDikt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwo_patch_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_patch48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                   prediction_basedir='../data')\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I\\'m done continued testing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/net/utils/train_h.py\u001b[0m in \u001b[0;36mquick_test\u001b[0;34m(model, addition_str, big_image_size, do_all, draw_img_ext, test_batch_size, just_draw_from_prediction, draw_better_mistakes, split_map, conf_dikt, two_patch_instance, prediction_basedir)\u001b[0m\n\u001b[1;32m    435\u001b[0m                           \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_expand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeploy_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                           \u001b[0;34m,\u001b[0m\u001b[0msubsample_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         do_dnnEnc=two_patch_instance)\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0moutput_prediction_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjust_draw_from_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/net/utils/test_predictions_funcs.py\u001b[0m in \u001b[0;36mcreate_prediction\u001b[0;34m(model, output_file, patcher_args, patch_size, do_expand, deploy_batch_size, subsample_mask, do_dnnEnc, split_patch)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mtype_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatches_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_expand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_expand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubsample_patch_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 do_special=None)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/data_prep/utils/patcher.py\u001b[0m in \u001b[0;36mimage_iterator_new\u001b[0;34m(filename, test_path, groundtruth_path, type, patches, save_path, PATCH_DIR, do_expand, patch_size, do_print, do_patch, subsample_patch_mask, do_special)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             \u001b[0msubsample_patch_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_patch_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                         \u001b[0mdo_expand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_expand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_print\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_patch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                         do_special=do_special)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished patching: {:.2f} secs.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/data_prep/utils/patcher.py\u001b[0m in \u001b[0;36mpatch_image_expand_new\u001b[0;34m(image_path, window_size, groundtruth_path, output_namebase, patches_per_image, set_type, save_path, PATCH_DIR, file_key, subsample_patch_mask, do_expand, do_print, do_patch, do_special)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 patches.append(cut_new(expanded_image,gnd_new_image,pixel_x,pixel_y,\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                     border_bar,output_namebase,set_type,save_path,do_expand=do_expand,do_patch=do_patch ))\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/data_prep/utils/patcher.py\u001b[0m in \u001b[0;36mcut_new\u001b[0;34m(expanded_image, groundtruth_image, pixel_x, pixel_y, border_bar, output_namebase, set_type, save_path, do_expand, do_patch)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpanded_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpixel_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mborder_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpixel_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mborder_bar\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mborder_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpixel_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mborder_bar\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_parDikt={\n",
    "    'patch_size':45,\n",
    "    'img_path':r'../test_data/possible_dnn_input',\n",
    "    'groundtruth':r'../test_data/Consensus corrected',\n",
    "    'interim':r'../test_data/possible_dnn_input'}\n",
    "\n",
    "\n",
    "save_model_loc = r'../test_data/weights_wdog.hdf5'\n",
    "\n",
    "full_set_description='MLset01_images'\n",
    "set_iter=zip(range(0,62,1),range(1,62,1),range(1))\n",
    "\n",
    "if not newTrain:\n",
    "    print('Continued Training')\n",
    "\n",
    "    # model=load_model(save_model_loc,\n",
    "        #custom_objects={'CRBMPretrained':CRBMPretrained})\n",
    "    model=load_model(save_model_loc,\n",
    "                     custom_objects={'AutoEncoderLayer':\n",
    "                            net_utils.AutoEncoderLayer.AutoEncoderLayer})\n",
    "\n",
    "    quick_oldstr=save_model_loc[:save_model_loc.index('.')]\n",
    "    quick_oldstr+=full_set_description\n",
    "\n",
    "    for older,newer,xx in set_iter:\n",
    "\n",
    "        test_parDikt.update({'from': older, 'to': newer})\n",
    "\n",
    "        quick_test(model, quick_oldstr, big_img_size, do_all=do_whole_pic,\n",
    "                   draw_img_ext=draw_img_ext, test_batch_size=50,\n",
    "                   split_map=split_patches,\n",
    "                   conf_dikt=test_parDikt,two_patch_instance=start_patch48,\n",
    "                  prediction_basedir='../data')\n",
    "    sys.exit('I\\'m done continued testing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLZWpeq7whT1"
   },
   "source": [
    "## New Training\n",
    "\n",
    "### setup dnn specific parameters\n",
    "\n",
    "1. Getting the model architecture (specified elsewhere);\n",
    "2. Setting training callbacks, currently active:\n",
    "    1. Save model every training epoch\n",
    "    3. Early stop training, if val-acc smoothens.\n",
    "    5. Draw full EM image after 1 epoch trained\n",
    "    6. Log Losses during training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9OrDtSFlwhT2"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-86f3572cdffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                   metrics=['accuracy'])\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mconfig_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_relevant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_quickmodels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquick_str\u001b[0m\u001b[0;34m,\u001b[0m                          \u001b[0mjust_return\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/net/utils/train_h.py\u001b[0m in \u001b[0;36msave_relevant\u001b[0;34m(savedir, add_str, files, str_to_save, just_return, descriptive_text)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mstr_to_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mone_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models.py'"
     ]
    }
   ],
   "source": [
    "\n",
    "if newTrain:\n",
    "    print('New Training')\n",
    "    model = get_2k_image_pretrained(img_w, img_h,added_stuff,\\\n",
    "                                    ch_add=numchannel_autoenc)\n",
    "\n",
    "    model_epoch=0\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "## Implemented in .py files\n",
    "config_text='#####NOT ACTIVE####'\n",
    "\n",
    "#save_relevant('saved_quickmodels', quick_str,\\\n",
    "#                          just_return=True)\n",
    "\n",
    "\n",
    "\n",
    "# reduce_lr_call=ReduceLROnPlateau(monitor='val_acc',factor=0.2,\n",
    "#                                  patience=3,cooldown=2,verbose=1)\n",
    "save_model_call=ModelCheckpoint(os.path.join(\n",
    "        model_locs,weights_prepend+'.{epoch:02d}-{val_acc:.4f}.hdf5'),\n",
    "                                verbose=1,monitor='val_acc'\n",
    "                                )\n",
    "\n",
    "earlystop_call=EarlyStopping(monitor='val_acc', \n",
    "                             min_delta=0.0001, patience=5,\n",
    "                             verbose=1, mode='auto')\n",
    "# tensor_call=TensorBoard(log_dir=log_loc, histogram_freq=3,\n",
    "# write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dodraw_afterone=LambdaCallback(\n",
    "    on_epoch_end=partial(draw_onfirst_epoch,\n",
    "                         model=model,\n",
    "                         big_img_size=big_img_size,\n",
    "                         do_test=do_test_after_one,\n",
    "                         quick_str=quick_str,\n",
    "                         str_to_save=config_text,\n",
    "                         split_map=split_patches))\n",
    "\n",
    "\n",
    "\n",
    "log_losses=LogLossesCallback(val_freq//batch_size,(val_freq*3)//batch_size,model_id=quick_str,\n",
    "                             save_loc=train_autoenc_loc,save_model=r'D:\\data_projects\\neuron_fibers_data\\autoenc')\n",
    "\n",
    "all_calls=[save_model_call,earlystop_call,dodraw_afterone]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GlxCrwGwhT5"
   },
   "source": [
    "## Executing Training\n",
    "\n",
    "\n",
    "* Actually training the DNN, using lmdb databases to obtain **input data**.\n",
    "\n",
    "Code stops after the specified training epochs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZjlBYDtqwhT6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "start_t=time.time()\n",
    "\n",
    "\n",
    "lmdbval_env=lmdb.open(val_lmdb)\n",
    "lmdbval_txn=lmdbval_env.begin()\n",
    "\n",
    "lmdbtrain_env=lmdb.open(train_lmdb)\n",
    "lmdbtrain_txn=lmdbtrain_env.begin()\n",
    "train_size=lmdbtrain_env.stat()['entries']\n",
    "val_size=int(lmdbval_env.stat()['entries']*reduce_valSize_Fac)\n",
    "\n",
    "\n",
    "oneI=iterate_indef(lmdbval_txn, batch_size, img_w *2 if start_patch48 else img_w, img_h, two_patch_instance=start_patch48,\n",
    "              do_continuous=True,\n",
    "                   do_single_patch=single_map_autoenc,\n",
    "                   split_map=split_patches,return_dnn_annotation=True)\n",
    "\n",
    "raw_patches=[next(oneI) for ind in range(4)]\n",
    "val_data_x,val_data_y=arr([i[0] for i in raw_patches]),arr([i[1] for i in raw_patches])\n",
    "oneI=None\n",
    "log_losses.val_data=val_data_x.reshape((4*batch_size,)+val_data_x.shape[2:]),val_data_y.reshape((4*batch_size,)+val_data_y.shape[2:])\n",
    "\n",
    "model.fit_generator(\n",
    "    iterate_indef(lmdbtrain_txn,batch_size,img_w *2 if start_patch48 else img_w,img_h,\n",
    "                  do_continuous=True,\n",
    "        do_single_patch=single_map_autoenc,\n",
    "                  split_map=split_patches,two_patch_instance=start_patch48,return_dnn_annotation=True),\n",
    "            samples_per_epoch=train_size-train_size%batch_size,\n",
    "                    nb_epoch=epoch_count,\n",
    "\n",
    "          verbose=1,\n",
    "        callbacks=all_calls,\n",
    "        validation_data= \\\n",
    "        iterate_indef(lmdbval_txn, batch_size, img_w *2 if start_patch48 else img_w, img_h,\n",
    "                    do_single_patch=single_map_autoenc,\n",
    "                      do_continuous=True,split_map=split_patches,two_patch_instance=start_patch48,return_dnn_annotation=True),\n",
    "        nb_val_samples=val_size-val_size%batch_size )\n",
    "\n",
    "\n",
    "lmdbtrain_env.close()\n",
    "\n",
    "# score = model.evaluate_generator(\n",
    "#     iterate_indef(lmdbval_txn, batch_size, img_w, img_h, do_continuous=True),\n",
    "#         val_samples=val_size-val_size%batch_size, verbose=1)\n",
    "#\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "lmdbval_env.close()\n",
    "\n",
    "print('Fully done with training !')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfTdtlOtwhT8"
   },
   "source": [
    "## Possibly testing DNN after training\n",
    "\n",
    "* Code to draw images after the training, specifically using a **CRBM** pretrained layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UDEF4AUqwhT9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if do_quick_after_train:\n",
    "    best_model_loc=use_num_model(quick_str,num_model=epoch_toDraw)\n",
    "    best_model=load_model(best_model_loc,custom_objects={'CRBMPretrained':CRBMPretrained})\n",
    "\n",
    "    quick_test(best_model,quick_str,big_img_size,do_all=do_whole_pic\n",
    "               ,split_map=split_patches,draw_img_ext=draw_img_ext)\n",
    "    # save_relevant('saved_quickmodels',quick_str)\n",
    "\n",
    "if test_after_train_fullset:\n",
    "\n",
    "    quick_str += 'fullset'\n",
    "    for older, newer in zip(range(0, 31, 8), range(8, 33, 8)):\n",
    "        test_parDikt.update({'from':older,'to':newer})\n",
    "\n",
    "        quick_test(model, quick_str, big_img_size, do_all=do_whole_pic, \n",
    "                   draw_img_ext=draw_img_ext, test_batch_size=500,\n",
    "                   split_map=split_patches,\n",
    "                   conf_dikt=test_parDikt)\n",
    "\n",
    "print('time duration is: ',time.time()-start_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LR9abcVxw4hT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Operating a DNN Instance.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
