{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operating DNN Pixel Classifier Model\n",
    "\n",
    "\n",
    "This module is about training/testing a deep neural network, using a basic architecture of a pixel classifier ( originally proposed by <sup>   [[ciresan2012]](http://people.idsia.ch/~ciresan/data/nips2012.pdf)</sup>).\n",
    "\n",
    "+ The specific neural network model used, is defined elsewhere (`net/utils/models.py`).\n",
    "\n",
    "\n",
    "\n",
    "![DNN Model](https://i.imgur.com/hC3AL1b.png)\n",
    "This image gives an overview of the basic architecture.\n",
    "\n",
    "#### Basically the NN is constructed from densifying pyramidal blocks of (conv-relu; maxpool) NN layers.\n",
    "\n",
    "#### The first layer can have **copied weights**, taken from a previously trained AEN model.\n",
    "\n",
    "\n",
    "Using this notebook, a DNN model can be:\n",
    " 1. Trained from a lmdb training database, with specific train parameters;\n",
    " 2. Tested using a full **interim** image set input, to generate _\"cleared\"_ **DNN Corrected** representations.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViHv0jwqwhTk"
   },
   "source": [
    "# Importing modules\n",
    "\n",
    "Importing all dependent python functions for training a DNN.\n",
    "\n",
    "The main computational frameworks used were:\n",
    "+ [Keras](https://keras.io/) as a high level DNN Python API.\n",
    "+ [Tensorflow](https://www.tensorflow.org/) as a low level GPU processing framework.\n",
    "\n",
    "Additionally [LMDB](https://lmdb.readthedocs.io/) was used as a database API for data managment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jsP-NmUZwhTl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every import is succesful !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from numpy import array as arr\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard,EarlyStopping,LambdaCallback\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dnn_segmentation.net.utils as net_utils\n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.train_h import iterate_indef\n",
    " \n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.train_h import \\\n",
    "    quick_test,get_session,draw_onfirst_epoch,save_relevant,\\\n",
    "    use_best_model,use_num_model\n",
    "\n",
    "from dnn_segmentation.net.utils.models import \\\n",
    "    get_2k_image_good_convmodel,get_2k_twopath_simple,\\\n",
    "    get_2k_twopath_twoconv,get_2k_image_pretrained, \\\n",
    "    get_2k_image_2layer_convnetmodel\n",
    "    \n",
    "print('Every import is succesful !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5v2IYIGwhTp"
   },
   "source": [
    "## Setting training/testing parameters\n",
    "\n",
    "Here all training/testing parameters before processing are set.\n",
    "\n",
    "Mainly they can be divided in:\n",
    "1. Boolean Configuration Flag  \n",
    "\n",
    "   + Train a **New** DNN Model, \n",
    "    \n",
    "   + **Predict** with an existing model to _\"correct\"_ a full image set.\n",
    "    \n",
    "1. Model, Data **path locations**;\n",
    "2. Input image/patch info;\n",
    "3. DNN training info\n",
    "    1. optimiser\n",
    "    2. batch size\n",
    "    3. num of train epochs\n",
    "4. Other programatical processing flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "68WCLUoTwhTq"
   },
   "outputs": [],
   "source": [
    "# DNN Main Processing FLAG\n",
    "newTrain=False\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(None)\n",
    "KTF.set_session(get_session(0.8))\n",
    "\n",
    "\n",
    "model_locs=r'../test_data'\n",
    "log_loc=r'../test_data/logs'  # Not used, tensorflow log location\n",
    "\n",
    "\n",
    "val_lmdb=r'######/val_db'\n",
    "train_lmdb=r'####/train_db'\n",
    "\n",
    "img_w,img_h=45,45\n",
    "big_img_size=2048\n",
    "\n",
    "# optimizer = SGD(lr=0.0001, decay=0.0005, \n",
    "# momentum=0.9, nesterov=True)\n",
    "optimizer='adadelta'\n",
    "\n",
    "loss_func='categorical_crossentropy' \n",
    "\n",
    "batch_size=500\n",
    "epoch_count=3\n",
    "\n",
    "\n",
    "#  Random short nametag, for every new model experiment.\n",
    "quick_str=''.join(map(chr,np.random.randint(97,97+26,(4,))) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "split_patches=True  # true for autoenc\n",
    "\n",
    "single_map_autoenc=False #true for single autoenc\n",
    "numchannel_autoenc=3 # true for..1\n",
    "\n",
    "\n",
    "epoch_toDraw=None # None for best epoch\n",
    "start_patch48=True  # true for autoenc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kL-p-aIwhTt"
   },
   "source": [
    "## Aditional setup parameters\n",
    "\n",
    "* Setting **pretraining** parameters\n",
    " 1. Crbm based pretraining\n",
    " 2. Autoenc based pretraining\n",
    "* Setting validation frequency\n",
    "* Other flags\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "noJGNmVHwhTu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model is:  weights_data_vjat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "added_stuff={\n",
    "            # 'path_pretrain':\n",
    "            #      r'crmb_model_valloss_3333.npy',\n",
    "    'use_crbm':False,\n",
    "    'use_autoenc':True,\n",
    "             'autoenc_loc':r'../test_data/weights_autoenc_gced.00-0.1958.hdf5',\n",
    "             'autoenc_layer':'convolution2d_1'}\n",
    "\n",
    "train_autoenc_loc=r'../test_data/autoenc_train'\n",
    "reduce_valSize_Fac=0.2 # 1\n",
    "\n",
    "do_quick_after_train=False\n",
    "do_test_after_one=False\n",
    "test_after_train_fullset=False\n",
    "\n",
    "\n",
    "do_whole_pic=True\n",
    "draw_img_ext='*.tif'\n",
    "val_freq=122300\n",
    "\n",
    "\n",
    "weights_prepend='weights_data_'+quick_str\n",
    "\n",
    "\n",
    "print('New Model is: ',weights_prepend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RlP3YotwhTw"
   },
   "source": [
    "## DNN Correcting Images\n",
    "\n",
    "\n",
    "### (skip if new DNN training) \n",
    "\n",
    "This codeblock is for _\"testing\"_ a previously trained DNN module.\n",
    "\n",
    "\n",
    "For start, some configurtation parameters:\n",
    "+ Location path of data, image sets;\n",
    "+ Correcting DNN model location;\n",
    "+ Correcting experiment tag;\n",
    "+ Image set iterator\n",
    "\n",
    "With the configuration, \n",
    "\n",
    "the code iteratively uses the DNN to _\"clean\"_ the input **interim** patches, (subset from the full EM **preprocessed** images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tqP68ibgwhTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continued Training\n",
      "['../test_data/possible_dnn_input/sp13726-img05-interim.tif'] 0 1 ../test_data/possible_dnn_input\n",
      "Drawing on these:  1 ['../test_data/possible_dnn_input/sp13726-img05-interim.tif']\n",
      "Testing started - 3.498679\n",
      "Running on img:sp13726-img05-interim.tif\n",
      "Starting patching on image:  sp13726-img05  ...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        "
      
     ]
    }
   ],
   "source": [
    "test_parDikt={\n",
    "    'patch_size':45,\n",
    "    'img_path':r'../test_data/possible_dnn_input',\n",
    "    'groundtruth':r'../test_data/Consensus corrected',\n",
    "    'interim':r'../test_data/possible_dnn_input'}\n",
    "\n",
    "\n",
    "save_model_loc = r'../test_data/weights_wdog.hdf5'\n",
    "\n",
    "full_set_description='MLset01_images'\n",
    "set_iter=zip(range(0,62,1),range(1,62,1),range(1))\n",
    "\n",
    "if not newTrain:\n",
    "    print('Continued Training')\n",
    "\n",
    "    # model=load_model(save_model_loc,\n",
    "        #custom_objects={'CRBMPretrained':CRBMPretrained})\n",
    "    model=load_model(save_model_loc,\n",
    "                     custom_objects={'AutoEncoderLayer':\n",
    "                            net_utils.AutoEncoderLayer.AutoEncoderLayer})\n",
    "\n",
    "    quick_oldstr=save_model_loc[:save_model_loc.index('.')]\n",
    "    quick_oldstr+=full_set_description\n",
    "\n",
    "    for older,newer,xx in set_iter:\n",
    "\n",
    "        test_parDikt.update({'from': older, 'to': newer})\n",
    "\n",
    "        quick_test(model, quick_oldstr, big_img_size, do_all=do_whole_pic,\n",
    "                   draw_img_ext=draw_img_ext, test_batch_size=50,\n",
    "                   split_map=split_patches,\n",
    "                   conf_dikt=test_parDikt,two_patch_instance=start_patch48,\n",
    "                  prediction_basedir='../data')\n",
    "    sys.exit('I\\'m done continued testing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLZWpeq7whT1"
   },
   "source": [
    "## New Training\n",
    "\n",
    "### setup dnn specific parameters\n",
    "\n",
    "1. Getting the model architecture (specified elsewhere);\n",
    "2. Setting training callbacks, currently active:\n",
    "    1. Save model every training epoch\n",
    "    3. Early stop training, if val-acc smoothens.\n",
    "    5. Draw full EM image after 1 epoch trained\n",
    "    6. Log Losses during training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9OrDtSFlwhT2"
   },
   "outputs": [],
   "source": [
    "\n",
    "if newTrain:\n",
    "    print('New Training')\n",
    "    model = get_2k_image_pretrained(img_w, img_h,added_stuff,\\\n",
    "                                    ch_add=numchannel_autoenc)\n",
    "\n",
    "    model_epoch=0\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "## Implemented in .py files\n",
    "config_text='#####NOT ACTIVE####'\n",
    "\n",
    "#save_relevant('saved_quickmodels', quick_str,\\\n",
    "#                          just_return=True)\n",
    "\n",
    "\n",
    "\n",
    "# reduce_lr_call=ReduceLROnPlateau(monitor='val_acc',factor=0.2,\n",
    "#                                  patience=3,cooldown=2,verbose=1)\n",
    "save_model_call=ModelCheckpoint(os.path.join(\n",
    "        model_locs,weights_prepend+'.{epoch:02d}-{val_acc:.4f}.hdf5'),\n",
    "                                verbose=1,monitor='val_acc'\n",
    "                                )\n",
    "\n",
    "earlystop_call=EarlyStopping(monitor='val_acc', \n",
    "                             min_delta=0.0001, patience=5,\n",
    "                             verbose=1, mode='auto')\n",
    "# tensor_call=TensorBoard(log_dir=log_loc, histogram_freq=3,\n",
    "# write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dodraw_afterone=LambdaCallback(\n",
    "    on_epoch_end=partial(draw_onfirst_epoch,\n",
    "                         model=model,\n",
    "                         big_img_size=big_img_size,\n",
    "                         do_test=do_test_after_one,\n",
    "                         quick_str=quick_str,\n",
    "                         str_to_save=config_text,\n",
    "                         split_map=split_patches))\n",
    "\n",
    "\n",
    "\n",
    "# log_losses=net_utils.LogLossesCallback.LogLossesCallback(val_freq//batch_size,(val_freq*3)//batch_size,model_id=quick_str,\n",
    "#                              save_loc=train_autoenc_loc,save_model=r'D:\\data_projects\\neuron_fibers_data\\autoenc')\n",
    "\n",
    "all_calls=[save_model_call,earlystop_call,dodraw_afterone]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GlxCrwGwhT5"
   },
   "source": [
    "## Executing Training\n",
    "\n",
    "\n",
    "* Actually training the DNN, using lmdb databases to obtain **input data**.\n",
    "\n",
    "Code stops after the specified training epochs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZjlBYDtqwhT6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "start_t=time.time()\n",
    "\n",
    "\n",
    "lmdbval_env=lmdb.open(val_lmdb)\n",
    "lmdbval_txn=lmdbval_env.begin()\n",
    "\n",
    "lmdbtrain_env=lmdb.open(train_lmdb)\n",
    "lmdbtrain_txn=lmdbtrain_env.begin()\n",
    "train_size=lmdbtrain_env.stat()['entries']\n",
    "val_size=int(lmdbval_env.stat()['entries']*reduce_valSize_Fac)\n",
    "\n",
    "\n",
    "oneI=iterate_indef(lmdbval_txn, batch_size, img_w *2 if start_patch48 else img_w, img_h, two_patch_instance=start_patch48,\n",
    "              do_continuous=True,\n",
    "                   do_single_patch=single_map_autoenc,\n",
    "                   split_map=split_patches,return_dnn_annotation=True)\n",
    "\n",
    "raw_patches=[next(oneI) for ind in range(4)]\n",
    "val_data_x,val_data_y=arr([i[0] for i in raw_patches]),arr([i[1] for i in raw_patches])\n",
    "oneI=None\n",
    "log_losses.val_data=val_data_x.reshape((4*batch_size,)+val_data_x.shape[2:]),val_data_y.reshape((4*batch_size,)+val_data_y.shape[2:])\n",
    "\n",
    "model.fit_generator(\n",
    "    iterate_indef(lmdbtrain_txn,batch_size,img_w *2 if start_patch48 else img_w,img_h,\n",
    "                  do_continuous=True,\n",
    "        do_single_patch=single_map_autoenc,\n",
    "                  split_map=split_patches,two_patch_instance=start_patch48,return_dnn_annotation=True),\n",
    "            samples_per_epoch=train_size-train_size%batch_size,\n",
    "                    nb_epoch=epoch_count,\n",
    "\n",
    "          verbose=1,\n",
    "        callbacks=all_calls,\n",
    "        validation_data= \\\n",
    "        iterate_indef(lmdbval_txn, batch_size, img_w *2 if start_patch48 else img_w, img_h,\n",
    "                    do_single_patch=single_map_autoenc,\n",
    "                      do_continuous=True,split_map=split_patches,two_patch_instance=start_patch48,return_dnn_annotation=True),\n",
    "        nb_val_samples=val_size-val_size%batch_size )\n",
    "\n",
    "\n",
    "lmdbtrain_env.close()\n",
    "\n",
    "# score = model.evaluate_generator(\n",
    "#     iterate_indef(lmdbval_txn, batch_size, img_w, img_h, do_continuous=True),\n",
    "#         val_samples=val_size-val_size%batch_size, verbose=1)\n",
    "#\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "lmdbval_env.close()\n",
    "\n",
    "print('Fully done with training !')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfTdtlOtwhT8"
   },
   "source": [
    "## Possibly testing DNN after training\n",
    "\n",
    "* Code to draw images after the training, specifically using a **CRBM** pretrained layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UDEF4AUqwhT9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if do_quick_after_train:\n",
    "    best_model_loc=use_num_model(quick_str,num_model=epoch_toDraw)\n",
    "    best_model=load_model(best_model_loc,custom_objects={'CRBMPretrained':CRBMPretrained})\n",
    "\n",
    "    quick_test(best_model,quick_str,big_img_size,do_all=do_whole_pic\n",
    "               ,split_map=split_patches,draw_img_ext=draw_img_ext)\n",
    "    # save_relevant('saved_quickmodels',quick_str)\n",
    "\n",
    "if test_after_train_fullset:\n",
    "\n",
    "    quick_str += 'fullset'\n",
    "    for older, newer in zip(range(0, 31, 8), range(8, 33, 8)):\n",
    "        test_parDikt.update({'from':older,'to':newer})\n",
    "\n",
    "        quick_test(model, quick_str, big_img_size, do_all=do_whole_pic, \n",
    "                   draw_img_ext=draw_img_ext, test_batch_size=500,\n",
    "                   split_map=split_patches,\n",
    "                   conf_dikt=test_parDikt)\n",
    "\n",
    "print('time duration is: ',time.time()-start_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LR9abcVxw4hT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Operating a DNN Instance.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
