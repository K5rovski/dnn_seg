{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Data Preparation\n",
    "\n",
    "\n",
    "This python notebook deals with finding suitable training instances (around ROI fiber borders).\n",
    "\n",
    "This procedure relies on [ImageJ](https://imagej.net/Welcome) functions (specifically **threshold** and **analyze particles**), to create the ROI border image masks (saved using the **Draw** command).\n",
    "\n",
    "Specifically 2 ROI border masks were used:\n",
    "1. Big ROI cells - larger sampling window;\n",
    "2. Small ROI cells - smaller sampling window.\n",
    "\n",
    "There are additionally two [Jython Scripts](http://imagej.net/Jython_Scripting_Examples). \n",
    "They are located at `data_prep/sample/Find_Roi_Small(Big)_Cells.py`.\n",
    "\n",
    "---\n",
    "\n",
    "#### After ROI Border Image masks are obtained, this module can be executed.\n",
    "\n",
    "\n",
    "+ The output of this processing step is a set of sampling image masks -- in which every **non-zero** pixel represents a selected training instance.\n",
    "+ Instances are selected by applying a sampling random window along every ROI border.\n",
    "+ Additionally instances are randomly selected around debri pixels (pixels set as **BACKGROUND** in annotation image).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-vsIXRauZCw"
   },
   "source": [
    "## Importing Modules\n",
    "\n",
    "Here we import the needed python functions for sampling ROIs.\n",
    "\n",
    "+ The main data processing is done using the [Numpy](http://www.numpy.org/) Scientific Computing Framework.\n",
    "\n",
    "Also the Whole Package Help is displayed, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m6Uk4Dy1uZCx",
    "outputId": "5e9889d3-0845-42df-8619-7f3b7fdaa8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package dnn_segmentation:\n",
      "\n",
      "NAME\n",
      "    dnn_segmentation - # FrontalLobe_DNN_Seg\n",
      "\n",
      "DESCRIPTION\n",
      "    Main package for DNN Segmentation on Neuron Fibers.\n",
      "    \n",
      "    Containing 3 main modules\n",
      "    \n",
      "    1. Data Preparation\n",
      "       + Choosing Sampling Instances\n",
      "       + Saving Training Instances in a lmdb base, for convinience.\n",
      "    2. Neural Networks Processing\n",
      "       + Pretraining Module (Autoencoder or Convolutional RBM network) \n",
      "       + Deep Neural Network (Using to DNN correct pre-processed images.)\n",
      "    3. Ray Measuring Neuron fiber ROIs\n",
      "       + Ray Measuring ROIs\n",
      "       + Matching ROIs between two sets (Annotation, DNN Corrected)\n",
      "       + Discarding some DNN Damaged ROIs\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    data_prep (package)\n",
      "    net (package)\n",
      "    raym (package)\n",
      "\n",
      "FILE\n",
      "    /media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/__init__.py\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every import is succesful !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "print(help(\"dnn_segmentation\"))\n",
    "\n",
    "from dnn_segmentation.data_prep.utils.sample_set_funcs import get_good_patches,ConfigSample\n",
    "from dnn_segmentation.net.utils.train_h import save_relevant\n",
    "\n",
    "print('Every import is succesful !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66f0UJc8uZC4"
   },
   "source": [
    "\n",
    "## Experiment Basic Setup\n",
    "\n",
    "+ Code to set the random seed\n",
    "+ Save the current processing configuration (all conf files in current dir.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "B5QWPv6luZC5"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(8)\n",
    "#np.random.seed(None)\n",
    "\n",
    "\n",
    "#  Sampling Experiment ID\n",
    "experiment_id='sample_'+''.join(map(chr,np.random.randint(97,97+26,(5,))) )\n",
    "\n",
    "conf_test_tosave=save_relevant('saved_confs',experiment_id,\n",
    "            files=[ f for f in os.listdir('.') \n",
    "                   if os.path.isfile(f) and not f.endswith('.pyc')],\n",
    "            just_return=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDqGkJyxuZC9"
   },
   "source": [
    "\n",
    "# EXPERIMENT SETUP PARAMETERS\n",
    "\n",
    "Setting the actual sampling specific parameters:\n",
    "\n",
    "1. Description Text;\n",
    "2. Lookup Paths;\n",
    "\n",
    "\n",
    "3. ROI Sampling Parameters;\n",
    "4. Noise (Uniform) Sampling Parameters;\n",
    "5. ROI Noise Sampling Parameters, not used currently\n",
    "\n",
    "\n",
    "6. Training image shortcodes, (sampling is usually applied on 20 images, train subselection)\n",
    "\n",
    "The testing sampling was uniformly distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "T1I1XGI0uZC9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tagging/Saving current configuration\n",
    "DESCRIPTION_TEXT='sample ONSET, onspecific settings'\n",
    "save_conf=True\n",
    "\n",
    "\n",
    "# lookup paths params-------\n",
    "lookup_path= {}\n",
    "lookup_path['groundtruth'] = r'/media/kiks/My_Files/working/dnn_seg/test/Consensus corrected'\n",
    "lookup_path['interim'] = r'/media/kiks/My_Files/working/dnn_seg/test/interim_used'\n",
    "lookup_path['bigc'] = r'/media/kiks/My_Files/working/dnn_seg/test/sample_bigcells'\n",
    "lookup_path['smallc'] = r'/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells'\n",
    "lookup_path['debri'] = '###################'\n",
    "conf=ConfigSample()\n",
    "\n",
    "# general sample params---\n",
    "conf.save_loc = r'/media/kiks/My_Files/working/dnn_seg/test/save_train_instances'\n",
    "conf.img_size=2400\n",
    "conf.win_offs_big = 35\n",
    "conf.win_sparsity_big = 0.12\n",
    "conf.win_offs_small = 5\n",
    "conf.win_sparsity_small = 0.15\n",
    "\n",
    "# noise unif params-------\n",
    "conf.win_offs_noise = 5\n",
    "conf.win_sparsity_noise = 0.15\n",
    "conf.noise_big_sparsity = 0.85\n",
    "conf.noise_val = 255\n",
    "\n",
    "# noise roi not used for now-----------------\n",
    "conf.dbscan_eps = 10\n",
    "conf.dbscan_mins = 20\n",
    "conf.win_offs = 22\n",
    "conf.win_noiseroi_spar = 0.08\n",
    "\n",
    "# pixel in interims-------------\n",
    "leave_pix_noise = 0.1\n",
    "pix_remove_thres = 50\n",
    "\n",
    "\n",
    "# sampling images params----\n",
    "train_images=['sp14484-img04', 'sp14485-img05', 'sp13909-img05', 'sp14240-img03', 'sp14069-img04',\n",
    " 'sp14250-img03', 'sp13750-img09', 'sp13750-img03', 'sp13880-img07',\n",
    " 'sp14069-img01', 'sp13909-img11', 'sp13909-img07', 'sp14370-img10',\n",
    " 'sp14240-img01', 'sp14245-img04', 'sp13726-img08', 'sp13880-img11',\n",
    " 'sp14485-img03', 'sp14485-img09', 'sp14370-img07']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFHW7ooGuZDA"
   },
   "source": [
    "## RUNNING THE SETUP CONFIGURATION\n",
    "\n",
    "1. Iterating all above images\n",
    "   * Creating an empty image mask;\n",
    "   * Iterating every ROI border point; \n",
    "   * Randomly choosing/drawing sample pixels (using a sample window centered at the border point;\n",
    "   * Saving the obtained mask file.\n",
    "   \n",
    "2. Saving the experiment configuration files (current code folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "345r2H4ruZDB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groundtruth image set- has 30 images\n",
      "interim image set- has 30 images\n",
      "bigc image set- has 19 images\n",
      "smallc image set- has 19 images\n",
      "Iterating all images...\n",
      "img is:  0 / 3 51402 0.008923958333333334\n",
      "/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells/mask_sp13726-img08-interim.tif\n",
      "img is:  1 / 3 75667 0.013136631944444444\n",
      "/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells/mask_sp13909-img05-interim.tif\n",
      "img is:  2 / 3 76336 0.013252777777777778\n",
      "/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells/mask_sp13909-img07-interim.tif\n",
      "len good_patches:  126036\n",
      "len good_patches:  213805\n",
      "len good_patches:  149644\n",
      "all lens are:  1237011\n",
      "3 ['/media/kiks/My_Files/working/dnn_seg/test/Consensus corrected/sp13726-img08-corrected.tif', '/media/kiks/My_Files/working/dnn_seg/test/Consensus corrected/sp13909-img05-corrected.tif', '/media/kiks/My_Files/working/dnn_seg/test/Consensus corrected/sp13909-img07-corrected.tif'] 1237011\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(conf.save_loc):\n",
    "    os.makedirs(conf.save_loc)\n",
    "\n",
    "\n",
    "\n",
    "test_images = {}\n",
    "for pic_type in 'groundtruth;interim;bigc;smallc'.split(';'):\n",
    "    print ('{} image set- has {} images'.format(pic_type,\n",
    "                        len(glob.glob(os.path.join(lookup_path[pic_type], '*.tif'))) ) )\n",
    "    \n",
    "    \n",
    "    test_images[pic_type] = [filename for ind, filename in\n",
    "                             enumerate(glob.glob(os.path.join(lookup_path[pic_type], \n",
    "                                                              '*.tif')))\n",
    "         if filename[filename.rindex('sp'):filename.rindex('img') + 5] \\\n",
    "         in train_images]\n",
    "    test_images[pic_type].sort(key=lambda name: name[name.rindex('sp'):])\n",
    "\n",
    "\n",
    "print( len(test_images['groundtruth']), test_images['groundtruth'],\n",
    "\n",
    "get_good_patches(test_images, conf.save_loc, conf.win_offs,conf) )\n",
    "\n",
    "\n",
    "if save_conf:\n",
    "    save_relevant('saved_confs',experiment_id,\n",
    "                  str_to_save=conf_test_tosave,descriptive_text=DESCRIPTION_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "De2WL1-RuZDD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Sampling Training Instances.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
