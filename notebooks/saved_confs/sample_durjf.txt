Model for Prediction: sample_durjf is: 
------------
Description: sample ONSET, onspecific settings
Saving file: Operating a CRBM Instance.ipynb

===========
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convrbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b91a55df3c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myadlt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboltzmann\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvrbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from testing_vis import draw_someoutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miterate_unsup_indef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_split_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'convrbm'"
     ]
    }
   ],
   "source": [
    "from yadlt.models.boltzmann import convrbm\n",
    "import lmdb\n",
    "\n",
    "# from testing_vis import draw_someoutput\n",
    "from train_helper import iterate_unsup_indef, make_split_map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import itertools\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yadlt.models.boltzmann import convrbm\n",
    "import lmdb\n",
    "\n",
    "# from testing_vis import draw_someoutput\n",
    "from train_helper import iterate_unsup_indef, make_split_map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import itertools\n",
    "from skimage.io import imsave\n",
    "\n",
    "def draw_someoutput(matrices,save_picdir,savetxt):\n",
    "\n",
    "    if not os.path.exists(save_picdir):\n",
    "        os.makedirs(save_picdir)\n",
    "\n",
    "    one_dim=int(math.ceil(math.sqrt(matrices.shape[0])) )\n",
    "    one_allm = matrices.shape[1]+ (int(matrices.shape[1]/8.0) or 1)\n",
    "    big_mat=np.zeros((one_dim*one_allm,one_dim*one_allm))+matrices.max()\n",
    "\n",
    "    one_m=matrices.shape[1]\n",
    "    range_m=np.arange(one_dim)*one_allm\n",
    "\n",
    "    for mat,(onei,twoi) in zip(matrices,itertools.product(range_m,range_m)):\n",
    "        big_mat[onei:onei+one_m,twoi:twoi+one_m]=mat\n",
    "\n",
    "\n",
    "    print(matrices.shape,big_mat.shape,matrices.min())\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(big_mat,cmap='viridis')\n",
    "    plt.savefig( os.path.join(save_picdir,savetxt+ '.png'),dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "img_h,img_w=45,45\n",
    "image_size=(img_h,img_w,3)\n",
    "hidden_maps=80\n",
    "kernel_size=(4,4)\n",
    "learning_rate=0.0008\n",
    "batch_size=500\n",
    "num_epochs=3\n",
    "doSave=False\n",
    "visible_unit_type='bin'\n",
    "activation_type='softmax'\n",
    "\n",
    "\n",
    "# ===@   Modifing code -signal modifying parameters often as a rule\n",
    "save_pics_loc='crbm_80perc_normalprodset_normalsample_deep6_pics'# '########'\n",
    "name='crbm_80perc_normalprodset_normalsample_deep'\n",
    "\n",
    "model_loc=r'D:\\data_projects\\neuron_fibers_data\\models'\n",
    "\n",
    "# every 200x500 instances i.e. 100 000 instances\n",
    "save_inepoch=200\n",
    "\n",
    "\n",
    "if save_pics_loc is not None and not os.path.exists(save_pics_loc):\n",
    "    os.makedirs(save_pics_loc)\n",
    "\n",
    "\n",
    "r = convrbm.CONVRBM(image_size, hidden_maps,kernel_size,\n",
    "                    visible_unit_type=visible_unit_type,\n",
    "        name=name, loss_func='mse', learning_rate=learning_rate,\n",
    "                    activation_type=activation_type,\n",
    "\n",
    "                    model_separate_folder=model_loc,save_inepoch=save_inepoch,\n",
    "\n",
    "\n",
    "        regcoef=5e-4, regtype='none', gibbs_sampling_steps=3,stddev=0.1,\n",
    "            batch_size=batch_size, num_epochs=num_epochs,train_feedback=5)\n",
    "\n",
    "# Fit the model\n",
    "print('Start training...')\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "# train_lmdb='D:/NEURON_FIBER_DATA/lmdb_base_2k_45w_corrected_2mil_good/train_db'\n",
    "# val_lmdb='D:/NEURON_FIBER_DATA/lmdb_base_2k_45w_corrected_2mil_good/val_db'\n",
    "\n",
    "# train_lmdb='D:/NEURON_FIBER_DATA/lmdb_base_2k_45w_normal_mask_6milset_mixedset_80perc_20pics_prod/train_db'\n",
    "# val_lmdb='D:/NEURON_FIBER_DATA/lmdb_base_2k_45w_mask_6milset_normalset_prod/val_db'\n",
    "# #\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# lmdbval_env=lmdb.open(val_lmdb)\n",
    "# lmdbval_txn=lmdbval_env.begin()\n",
    "#\n",
    "# lmdbtrain_env=lmdb.open(train_lmdb)\n",
    "# lmdbtrain_txn=lmdbtrain_env.begin()\n",
    "\n",
    "# train_size=lmdbtrain_env.stat()['entries']#//5\n",
    "# val_size=12100#lmdbval_env.stat()['entries']\n",
    "#\n",
    "# print('Training {} instances'.format(train_size))\n",
    "#\n",
    "# train_size=int(train_size/batch_size)\n",
    "# val_size=int(val_size/batch_size)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "#\n",
    "# r.fit_generator(iterate_unsup_indef(lmdbtrain_txn,batch_size,img_w,img_h,do_continuous=True,\n",
    "#                                     divide_some=1.0,split_map=True),train_size,\n",
    "#\n",
    "#         iterate_unsup_indef(lmdbval_txn,batch_size,img_w,img_h,do_continuous=True,\n",
    "#                             divide_some=1.0,split_map=True),val_size)\n",
    "\n",
    "# ---------------------------\n",
    "#\n",
    "rbm_model_loc=r'D:\\data_projects\\neuron_fibers_data\\models\\mixedset_6mil_4kernel_80perc_{}_ep0_valloss_2280.npy'\n",
    "w_found = np.load(rbm_model_loc.format('Weight'))\n",
    "vbias = np.load(rbm_model_loc.format('vbias'))\n",
    "hbias = np.load(rbm_model_loc.format('hbias'))\n",
    "r.initialize_weights((w_found,vbias,hbias))\n",
    "\n",
    "\n",
    "# sumall=0.0\n",
    "# sumallsq=0.0\n",
    "# for patch in iterate_unsup_indef(lmdbtrain_txn,batch_size,img_w,img_h,do_continuous=False,divide_some=1.0,\n",
    "#                                  smallify_base=train_size):\n",
    "#     sumall+=np.average(patch.flatten())\n",
    "#     sumallsq+=np.average((patch**2 ).flatten())\n",
    "#\n",
    "# all_avg=sumall/train_size\n",
    "# all_avg_sq=sumallsq/train_size\n",
    "# standard_dev=math.sqrt(all_avg_sq-all_avg**2)\n",
    "\n",
    "\n",
    "\n",
    "# print('standard avg: ',all_avg,'standard_dev: ',standard_dev)\n",
    "\n",
    "# lmdbtrain_env.close()\n",
    "\n",
    "# real_vals=np.array(list(iterate_unsup_indef(lmdbval_txn,batch_size,\n",
    "#                                    img_w,img_h,do_continuous=False,\n",
    "#                                    smallify_base=val_size*batch_size,divide_some=1.0,split_map=True,\n",
    "#                                             split_list=[0,128,255])))\n",
    "#\n",
    "# real_vals=real_vals.reshape( (-1,)+image_size )\n",
    "#\n",
    "# real_vals=real_vals[ np.random.choice(real_vals.shape[0],batch_size,replace=False)]\n",
    "img=cv2.imread(r'D:\\data_projects\\neuron_fibers_data\\images\\test_spread_interim\\sp13909-img04-interim.tif' ,0)\n",
    "patch=img[834-22:834+23,676-22:676+23]\n",
    "\n",
    "xcor,ycor=1352,922\n",
    "xcor,ycor=1043,871\n",
    "xcor,ycor=1180,1192\n",
    "xcor,ycor=1458,1134\n",
    "xcor,ycor=1465,934\n",
    "\n",
    "\n",
    "patch=img[xcor-22:xcor+23,ycor-22:ycor+23]\n",
    "real_vals=make_split_map(patch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_recs,hidden_probs,hidden_outs=r.reconstruct(real_vals,return_hidden=True)\n",
    "\n",
    "# print('Some output',val_recs[:5,:2,:2])\n",
    "# draw_someoutput()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_recs_see=np.argmax(val_recs,axis=-1)\n",
    "\n",
    "real_vals_see=np.argmax(real_vals,axis=-1)\n",
    "\n",
    "\n",
    "if save_pics_loc is not None:\n",
    "    for i in range(real_vals.shape[0]):\n",
    "\n",
    "        cv2.imwrite( os.path.join(save_pics_loc, 'crbm_{}_real_pic.tif'.format(i))\n",
    "                     ,(real_vals_see[i] *127).astype(np.uint8) )\n",
    "\n",
    "        cv2.imwrite(os.path.join(save_pics_loc,'crbm_{}_restruction.tif'.format(i))\n",
    "                    , (val_recs_see[i]*127).astype(np.uint8)  )\n",
    "\n",
    "        for j in range(20):\n",
    "             imsave(os.path.join(save_pics_loc, 'crbm_{}_hidden_{}.tif'.format(i,j))\n",
    "                    ,((hidden_probs[0,:,:,j]/np.max(hidden_probs[:,:,:,j]))*255).astype(np.uint8),plugin='tifffile' )\n",
    "\n",
    "\n",
    "\n",
    "# draw_someoutput(real_vals_see[:25],'crbm_maps_good6milset_80perc','visible_input')\n",
    "# draw_someoutput(np.transpose(hidden_outs[3],(2,0,1)),'crbm_maps_good6milset_80perc','fourth_mat_hiddens2')\n",
    "\n",
    "print(mean_squared_error(real_vals.reshape(real_vals.shape[0],-1),val_recs.reshape(val_recs.shape[0],-1)))\n",
    "\n",
    "\n",
    "# score = model.evaluate_generator(\n",
    "#     iterate_indef(lmdbval_txn, batch_size, img_w, img_h, do_continuous=True),\n",
    "#         val_samples=val_size-val_size%batch_size, verbose=1)\n",
    "#\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "# lmdbval_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Saving file: Ray Measuring ROI Images.ipynb

===========
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confD={'raymeas_save_dir':r'D:\\data_projects\\neuron_fibers_data\\ray_measurements', \n",
    "'raymeas_add_id':'raym_17_04_29',  #'meta_info_mls02_gen'\n",
    "\n",
    "'match_add_id': 'match_17_04_29',  # 'AS_mls02_min_51p_autoenc_1ep'\n",
    "'postconds_id': 'postc_17_04_29',\n",
    "'base_meas_roiDir':'ROI_Imagej_MeasurementDir',\n",
    "'case_id_add1':'DNN',\n",
    "'case_id_add2':'CORR',\n",
    "\n",
    "\n",
    "\n",
    "'save_plot_arrays':1,\n",
    "\n",
    "\n",
    "\n",
    "'case1_picDir':r'D:\\data_projects\\neuron_fibers_data\\images\\predicted\\17_04_28_0.8454.mlset_interimON_6mil_pretrain_vntp\\gray',\n",
    "'base_dist_thres':80,\n",
    "'map_roi_thres':1,   # 1 for post conds, 3 for matches\n",
    "'strict_area_thres':0.6, #0.6\n",
    "'strict_dist_thres':20, #20\n",
    "'title_text':'\"DNN vs Corr...\"',\n",
    "'total_str': '',\n",
    "'afterc_str': '',\n",
    "'hist_title':'\"DNN post conds. vs Corr ROIs\"',\n",
    "'match_rois_sp2':0,  # Default: 0 for no match\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=['python','draw_gratio.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args.extend(['--{}={}'.format(item,val) for item,val in confD.items()])\n",
    "\n",
    "print(' '.join(args))\n",
    "\n",
    "\n",
    "run_attempt= subprocess.run(' '.join(args),stdout=PIPE,shell=True,cwd='.',\n",
    "\t\t\t\t\tstderr=PIPE)\n",
    "\n",
    "outp_str=run_attempt.stdout.decode('utf-8')\n",
    "err_str=run_attempt.stderr.decode('utf-8')\n",
    "print(err_str,outp_str)\n",
    "\n",
    "print('I am here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Saving file: Operating_a_DNN_Instance.ipynb

===========
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViHv0jwqwhTk"
   },
   "source": [
    "## Importing modules\n",
    "\n",
    "Importing all dependent python functions for training a DNN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jsP-NmUZwhTl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from numpy import array as arr\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard,EarlyStopping,LambdaCallback\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dnn_segmentation.net.utils as net_utils\n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.train_h import iterate_indef\n",
    "feurget_2k_image_2layer_convnetmodel \n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.train_h import \\\n",
    "    quick_test,get_session,draw_onfirst_epoch,save_relevant,use_best_model,use_num_model\n",
    "\n",
    "from dnn_segmentation.net.utils.models import \\\n",
    "    get_2k_image_good_convmodel,get_2k_twopath_simple,get_2k_twopath_twoconv,get_2k_image_pretrained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5v2IYIGwhTp"
   },
   "source": [
    "## Setting training/testing parameters\n",
    "\n",
    "Here all training/testing parameters before processing are set:\n",
    "1. Model,Data locations\n",
    "2. SPS Image information\n",
    "3. DNN Training information\n",
    "    1. Optimiser\n",
    "    2. Batch Size\n",
    "    3. Num of train Epochs\n",
    "    4. Other programatical processing flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "68WCLUoTwhTq"
   },
   "outputs": [],
   "source": [
    "np.random.seed(None)\n",
    "KTF.set_session(get_session(0.8))\n",
    "\n",
    "\n",
    "model_locs=r'/media/kiks/My_Files/working/dnn_seg/test'\n",
    "log_loc=r''\n",
    "\n",
    "\n",
    "val_lmdb=r'D:\\data_projects\\neuron_fibers_data\\BASES\\special_choice_8mil_45_Wsize_20imgs_interimONset\\val_db'\n",
    "train_lmdb=r'D:\\data_projects\\neuron_fibers_data\\BASES\\special_choice_8mil_45_Wsize_20imgs_interimONset\\train_db'\n",
    "\n",
    "img_w,img_h=45,45\n",
    "big_img_size=2400\n",
    "\n",
    "# optimizer = SGD(lr=0.0001, decay=0.0005, momentum=0.9, nesterov=True)\n",
    "optimizer='adadelta'\n",
    "\n",
    "loss_func='categorical_crossentropy' #'categorical_crossentropy'\n",
    "\n",
    "batch_size=500\n",
    "epoch_count=3\n",
    "\n",
    "\n",
    "quick_str=''.join(map(chr,np.random.randint(97,97+26,(4,))) )\n",
    "\n",
    "# False for new Training\n",
    "continueTrain=True\n",
    "\n",
    "\n",
    "justTestPreviousFullSet=True\n",
    "\n",
    "\n",
    "split_patches=True  # true for autoenc\n",
    "\n",
    "single_map_autoenc=False #true for single autoenc\n",
    "numchannel_autoenc=3 # true for..1\n",
    "\n",
    "\n",
    "epoch_toDraw=None # None for best epoch\n",
    "start_patch48=True  # true for autoenc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kL-p-aIwhTt"
   },
   "source": [
    "### Aditional setup parameters\n",
    "\n",
    "* Setting pretraining parameters\n",
    " 1. Crbm based pretraining\n",
    " 2. Autoenc based pretraining\n",
    "* Setting validation frequency\n",
    "* Other flags\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "noJGNmVHwhTu"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "added_stuff={\n",
    "            # 'path_pretrain':\n",
    "            #      r'C:\\Users\\kiko5\\.yadlt\\models\\crbm_80perc_normalprodset_normalsample_{}_ep0_valloss_3333.npy',\n",
    "    'use_crbm':False,\n",
    "    'use_autoenc':True,\n",
    "             'autoenc_loc':r'D:\\data_projects\\neuron_fibers_data\\models\\weights_autoenc_itjs.00-0.2338.hdf5',\n",
    "             'autoenc_layer':'convolution2d_1'}\n",
    "\n",
    "train_autoenc_loc=r'D:\\data_projects\\neuron_fibers_data\\autoenc'\n",
    "reduce_valSize_Fac=0.2 # 1\n",
    "\n",
    "do_quick_after_train=False\n",
    "do_test_after_one=False\n",
    "test_after_train_fullset=False\n",
    "\n",
    "\n",
    "do_whole_pic=True\n",
    "draw_img_ext='*.tif'\n",
    "val_freq=122300\n",
    "\n",
    "\n",
    "weights_prepend='weights_quickbig_'+quick_str\n",
    "\n",
    "\n",
    "print('Model is: ',weights_prepend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RlP3YotwhTw"
   },
   "source": [
    "## Just draw images\n",
    "#### No DNN training\n",
    "\n",
    "1. Testing Location Paths\n",
    "2. Iteratively DNN Correcting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tqP68ibgwhTz"
   },
   "outputs": [],
   "source": [
    "test_parDikt={\n",
    "    'patch_size':45,\n",
    "    'img_path':r'D:\\data_projects\\neuron_fibers_data\\images\\intsall\\\\',\n",
    "    'groundtruth':r'D:\\data_projects\\neuron_fibers_data\\images\\cors\\c\\\\',\n",
    "    'interim':r'D:\\data_projects\\neuron_fibers_data\\images\\intsall\\\\'}\n",
    "\n",
    "\n",
    "\n",
    "if continueTrain:\n",
    "    print('Continued Training')\n",
    "    save_model_loc = r'D:\\data_projects\\neuron_fibers_data\\models\\weights_quickbig_fosd.00-0.8676.hdf5'\n",
    "\n",
    "    # model=load_model(save_model_loc,custom_objects={'CRBMPretrained':CRBMPretrained})\n",
    "    model=load_model(save_model_loc,custom_objects={'AutoEncoderLayer':net_utils.AutoEncoderLayer.AutoEncoderLayer})\n",
    "\n",
    "    quick_oldstr=save_model_loc[save_model_loc.rindex('weights_quickbig')+15:save_model_loc.rindex('hdf5')]\n",
    "    # model_epoch=int(save_model_loc[save_model_loc.rindex(quick_oldstr)+4 +1:save_model_loc.rindex(quick_oldstr)+4 +3])\n",
    "\n",
    "    quick_oldstr+='mlset_interimON_8mil_ints_special_pretrain_normalized'\n",
    "\n",
    "    if justTestPreviousFullSet:\n",
    "        for older,newer,xx in zip(range(0,62,3),range(3,62,3),range(100)):\n",
    "\n",
    "            test_parDikt.update({'from': older, 'to': newer})\n",
    "\n",
    "            quick_test(model, quick_oldstr, big_img_size, do_all=do_whole_pic,\n",
    "                       draw_img_ext=draw_img_ext, test_batch_size=300,\n",
    "                       split_map=split_patches,\n",
    "                       conf_dikt=test_parDikt,two_patch_instance=start_patch48)\n",
    "        sys.exit('I\\'m done continued testing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLZWpeq7whT1"
   },
   "source": [
    "## New Training\n",
    "\n",
    "#### setup dnn specific parameters\n",
    "\n",
    "1. Using basic model architecture as specified\n",
    "2. Setting Training Callbacks, currently active:\n",
    " 3. Saving progressing training model\n",
    " 4. Early stop training if validation accuracy does not improve\n",
    " 5. Draw SPS image after 1 epoch trained\n",
    " 6. Log Losses during training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9OrDtSFlwhT2"
   },
   "outputs": [],
   "source": [
    "if not continueTrain:\n",
    "    print('New Training')\n",
    "    model = get_2k_image_pretrained(img_w, img_h,added_stuff,ch_add=numchannel_autoenc)\n",
    "\n",
    "    model_epoch=0\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "config_text=save_relevant('saved_quickmodels', quick_str,just_return=True)\n",
    "\n",
    "\n",
    "\n",
    "# reduce_lr_call=ReduceLROnPlateau(monitor='val_acc',factor=0.2,\n",
    "#                                  patience=3,cooldown=2,verbose=1)\n",
    "save_model_call=ModelCheckpoint(os.path.join(model_locs,weights_prepend+'.{epoch:02d}-{val_acc:.4f}.hdf5'),\n",
    "                                verbose=1,monitor='val_acc'\n",
    "                                )\n",
    "earlystop_call=EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "# tensor_call=TensorBoard(log_dir=log_loc, histogram_freq=3, write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dodraw_afterone=LambdaCallback(\n",
    "    on_epoch_end=partial(draw_onfirst_epoch,\n",
    "                         model=model,\n",
    "                         big_img_size=big_img_size,\n",
    "                         do_test=do_test_after_one,\n",
    "                         quick_str=quick_str,\n",
    "                         str_to_save=config_text,\n",
    "                         split_map=split_patches))\n",
    "\n",
    "\n",
    "\n",
    "log_losses=LogLossesCallback(val_freq//batch_size,(val_freq*3)//batch_size,model_id=quick_str,\n",
    "                             save_loc=train_autoenc_loc,save_model=r'D:\\data_projects\\neuron_fibers_data\\autoenc')\n",
    "\n",
    "all_calls=[save_model_call,earlystop_call,dodraw_afterone]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GlxCrwGwhT5"
   },
   "source": [
    "## Executing Training\n",
    "\n",
    "\n",
    "* Actually training the DNN, using lmdb databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZjlBYDtqwhT6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "start_t=time.time()\n",
    "\n",
    "\n",
    "lmdbval_env=lmdb.open(val_lmdb)\n",
    "lmdbval_txn=lmdbval_env.begin()\n",
    "\n",
    "lmdbtrain_env=lmdb.open(train_lmdb)\n",
    "lmdbtrain_txn=lmdbtrain_env.begin()\n",
    "train_size=lmdbtrain_env.stat()['entries']\n",
    "val_size=int(lmdbval_env.stat()['entries']*reduce_valSize_Fac)\n",
    "\n",
    "\n",
    "oneI=iterate_indef(lmdbval_txn, batch_size, img_w *2 if start_patch48 else img_w, img_h, two_patch_instance=start_patch48,\n",
    "              do_continuous=True,\n",
    "                   do_single_patch=single_map_autoenc,\n",
    "                   split_map=split_patches,return_dnn_annotation=True)\n",
    "\n",
    "raw_patches=[next(oneI) for ind in range(4)]\n",
    "val_data_x,val_data_y=arr([i[0] for i in raw_patches]),arr([i[1] for i in raw_patches])\n",
    "oneI=None\n",
    "log_losses.val_data=val_data_x.reshape((4*batch_size,)+val_data_x.shape[2:]),val_data_y.reshape((4*batch_size,)+val_data_y.shape[2:])\n",
    "\n",
    "model.fit_generator(\n",
    "    iterate_indef(lmdbtrain_txn,batch_size,img_w *2 if start_patch48 else img_w,img_h,\n",
    "                  do_continuous=True,\n",
    "        do_single_patch=single_map_autoenc,\n",
    "                  split_map=split_patches,two_patch_instance=start_patch48,return_dnn_annotation=True),\n",
    "            samples_per_epoch=train_size-train_size%batch_size,\n",
    "                    nb_epoch=epoch_count,\n",
    "\n",
    "          verbose=1,\n",
    "        callbacks=all_calls,\n",
    "        validation_data= \\\n",
    "        iterate_indef(lmdbval_txn, batch_size, img_w *2 if start_patch48 else img_w, img_h,\n",
    "                    do_single_patch=single_map_autoenc,\n",
    "                      do_continuous=True,split_map=split_patches,two_patch_instance=start_patch48,return_dnn_annotation=True),\n",
    "        nb_val_samples=val_size-val_size%batch_size )\n",
    "\n",
    "\n",
    "lmdbtrain_env.close()\n",
    "\n",
    "# score = model.evaluate_generator(\n",
    "#     iterate_indef(lmdbval_txn, batch_size, img_w, img_h, do_continuous=True),\n",
    "#         val_samples=val_size-val_size%batch_size, verbose=1)\n",
    "#\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "lmdbval_env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfTdtlOtwhT8"
   },
   "source": [
    "## Possibly testing after drawing\n",
    "\n",
    "* Code to draw images after the training, specifically using a CRBM pretrained layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UDEF4AUqwhT9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if do_quick_after_train:\n",
    "    best_model_loc=use_num_model(quick_str,num_model=epoch_toDraw)\n",
    "    best_model=load_model(best_model_loc,custom_objects={'CRBMPretrained':CRBMPretrained})\n",
    "\n",
    "    quick_test(best_model,quick_str,big_img_size,do_all=do_whole_pic\n",
    "               ,split_map=split_patches,draw_img_ext=draw_img_ext)\n",
    "    # save_relevant('saved_quickmodels',quick_str)\n",
    "\n",
    "if test_after_train_fullset:\n",
    "\n",
    "    quick_str += 'fullset'\n",
    "    for older, newer in zip(range(0, 31, 8), range(8, 33, 8)):\n",
    "        test_parDikt.update({'from':older,'to':newer})\n",
    "\n",
    "        quick_test(model, quick_str, big_img_size, do_all=do_whole_pic, draw_img_ext=draw_img_ext, test_batch_size=500,\n",
    "                   split_map=split_patches,\n",
    "                   conf_dikt=test_parDikt)\n",
    "\n",
    "print('time duration is: ',time.time()-start_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1530615037693,
     "user": {
      "displayName": "Kristijan Petrovski",
      "photoUrl": "//lh6.googleusercontent.com/-TWBf9dSre0I/AAAAAAAAAAI/AAAAAAAAMCU/7dudhu_17yE/s50-c-k-no/photo.jpg",
      "userId": "113901552029870575792"
     },
     "user_tz": -120
    },
    "id": "TvWXD-wZwxKu",
    "outputId": "ed27d908-684b-44b5-d90d-22725dfda687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content',\n",
       " ['datalab', '.ipython', '.forever', '.cache', '.config', '.local'])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd(),os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LR9abcVxw4hT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Operating a DNN Instance.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

Saving file: Operating an AEN Instance.ipynb

===========
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Functions\n",
    "\n",
    "**AEN Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from os.path import join\n",
    "\n",
    "import cv2\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dnn_segmentation.net.utils as net_utils\n",
    "\n",
    "\n",
    "from dnn_segmentation.net.utils.models import  get_autoencoded\n",
    "from dnn_segmentation.net.utils.train_h import iterate_indef, \\\n",
    "    get_session, make_split_map, draw_autoenc_smaller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KTF.set_session(get_session(0.8))\n",
    "\n",
    "train_lmdb=r'D:\\data_projects\\neuron_fibers_data\\BASES\\special_choice_8mil_45_Wsize_20imgs_interimONset\\train_db'\n",
    "val_lmdb=r'D:\\data_projects\\neuron_fibers_data\\BASES\\special_choice_8mil_45_Wsize_20imgs_interimONset\\val_db'\n",
    "\n",
    "model_locs=r'D:\\data_projects\\neuron_fibers_data\\models'\n",
    "log_loc=r'D:\\data_projects\\neuron_fibers_data\\tensor_logs'\n",
    "img_w,img_h=45,45\n",
    "big_img_size=2400\n",
    "\n",
    "# optimizer = SGD(lr=0.0001, decay=0.0005, momentum=0.9, nesterov=True)\n",
    "optimizer='adadelta'\n",
    "\n",
    "\n",
    "loss_func='categorical_crossentropy' #'categorical_crossentropy'\n",
    "\n",
    "batch_size=500\n",
    "epoch_count=1\n",
    "split_patches=True   #True for norml autoenc\n",
    "do_single_map=False    #False for normal autoenc\n",
    "\n",
    "np.random.seed(None)\n",
    "quick_str=''.join(map(chr,np.random.randint(97,97+26,(4,))) )\n",
    "\n",
    "weights_prepend='weights_autoenc_'+quick_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_locs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1709936296b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mhist_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'D:\\data_projects\\neuron_fibers_data\\autoenc\\history'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m save_model_call=ModelCheckpoint(os.path.join(model_locs,weights_prepend+'.{epoch:02d}-{val_loss:.4f}.hdf5'),\n\u001b[0m\u001b[1;32m      9\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                 )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_locs' is not defined"
     ]
    }
   ],
   "source": [
    "#!!!!!!!!!!!! Just drawing inside results\n",
    "doJustDrawEnc=True\n",
    "\n",
    "model_loc=r'D:\\data_projects\\neuron_fibers_data\\models\\weights_autoenc_dvov.00-0.2944.hdf5'\n",
    "draw_encoded_loc=r'D:\\code_projects\\dnn_seg\\autoenc\\encoded_maps_vis'\n",
    "hist_loc=r'D:\\data_projects\\neuron_fibers_data\\autoenc\\history'\n",
    "\n",
    "save_model_call=ModelCheckpoint(os.path.join(model_locs,weights_prepend+'.{epoch:02d}-{val_loss:.4f}.hdf5'),\n",
    "                                verbose=1,monitor='val_loss'\n",
    "                                )\n",
    "earlystop_call=EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "tensor_call=TensorBoard(log_dir=log_loc, histogram_freq=3, write_graph=True, write_images=True)\n",
    "\n",
    "log_losses=net_utils.LogLossesCallback(123500//batch_size,1,model_id=quick_str,save_loc=hist_loc)\n",
    "# LogLossesCallback()\n",
    "\n",
    "\n",
    "\n",
    "all_calls=[save_model_call,earlystop_call,tensor_call,log_losses]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DNN Corrected Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if doJustDrawEnc:\n",
    "    model=load_model(model_loc,custom_objects={'tf':tf})\n",
    "    mod_name=model_loc[model_loc.index('weights_autoenc_'):]\n",
    "    draw_loc=join(draw_encoded_loc,mod_name)\n",
    "    if not os.path.exists(draw_loc): os.makedirs(draw_loc)\n",
    "\n",
    "    patchs=[]\n",
    "\n",
    "    img1 = cv2.imread(r'D:\\data_projects\\neuron_fibers_data\\images\\test_spread_interim\\sp13909-img04-interim.tif', 0)\n",
    "    img2=cv2.imread(r'D:\\data_projects\\neuron_fibers_data\\images\\all_test_big_corrected\\sp13909-img04-corrected.tif',0)\n",
    "    for img in [img1,img2]:\n",
    "        patchs.append( img[834 - 22:834 + 23, 676 - 22:676 + 23])\n",
    "\n",
    "        xcor, ycor = 1352, 922\n",
    "        patchs.append(img[xcor - 22:xcor + 23, ycor - 22:ycor + 23])\n",
    "        xcor, ycor = 1043, 871\n",
    "        patchs.append(img[xcor - 22:xcor + 23, ycor - 22:ycor + 23])\n",
    "        xcor, ycor = 1180, 1192\n",
    "        patchs.append(img[xcor - 22:xcor + 23, ycor - 22:ycor + 23])\n",
    "        xcor, ycor = 1458, 1134\n",
    "        patchs.append(img[xcor - 22:xcor + 23, ycor - 22:ycor + 23])\n",
    "        xcor, ycor = 1465, 934\n",
    "        patchs.append(img[xcor - 22:xcor + 23, ycor - 22:ycor + 23])\n",
    "\n",
    "\n",
    "    patchs=np.array(patchs)\n",
    "\n",
    "\n",
    "    real_vals = make_split_map(patchs[:6],dopad=True)\n",
    "    real_vals2=make_split_map(patchs[6:],dopad=True,split_map=[1,2,3])\n",
    "    patches = np.zeros((2, 6, 48, 48, 3), dtype=np.uint8)\n",
    "    patches[0,:]=real_vals\n",
    "    patches[1,:]=real_vals2\n",
    "\n",
    "    draw_autoenc_smaller(model,draw_loc,patches)\n",
    "\n",
    "#    draw_autoenc(model, img_w, img_h, draw_loc, val_lmdb)\n",
    "    sys.exit('Im am done with everything!!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Pretraining AEN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "else:\n",
    "    model = get_autoencoded(img_w, img_h,)\n",
    "\n",
    "\n",
    "\n",
    "start_t=time.time()\n",
    "\n",
    "\n",
    "lmdbval_env=lmdb.open(val_lmdb)\n",
    "lmdbval_txn=lmdbval_env.begin()\n",
    "\n",
    "lmdbtrain_env=lmdb.open(train_lmdb)\n",
    "lmdbtrain_txn=lmdbtrain_env.begin()\n",
    "train_size=lmdbtrain_env.stat()['entries']\n",
    "val_size=83500#lmdbval_env.stat()['entries']\n",
    "\n",
    "oneI=iterate_indef(lmdbval_txn, batch_size, img_w * 2, img_h, two_patch_instance=True,\n",
    "              do_continuous=True, split_map=split_patches,do_single_patch=do_single_map)\n",
    "raw_patches=[next(oneI) for ind in range(5)]\n",
    "val_data_x,val_data_y=np.concatenate([i[0] for i in raw_patches]), \\\n",
    "                      np.concatenate([i[1] for i in raw_patches])\n",
    "oneI=None\n",
    "log_losses.val_data=val_data_x,val_data_y\n",
    "\n",
    "history_mod=model.fit_generator(\n",
    "    iterate_indef(lmdbtrain_txn,batch_size,img_w*2,img_h,\n",
    "                  do_continuous=True,split_map=split_patches,\n",
    "                  do_single_patch=do_single_map,two_patch_instance=True,),\n",
    "            samples_per_epoch=train_size-train_size%batch_size,\n",
    "                    nb_epoch=epoch_count,\n",
    "\n",
    "          verbose=1,\n",
    "        callbacks=all_calls,\n",
    "        validation_data= \\\n",
    "        iterate_indef(lmdbval_txn, batch_size, img_w*2, img_h,two_patch_instance=True,\n",
    "                      do_single_patch=do_single_map,do_continuous=True,split_map=split_patches),\n",
    "        nb_val_samples=val_size-val_size%batch_size )\n",
    "\n",
    "\n",
    "lmdbtrain_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possibly Validate AEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lmdbval_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e188d869a37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlmdbval_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lmdbval_env' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "score = model.evaluate_generator(\n",
    "    iterate_indef(lmdbval_txn, batch_size, img_w, img_h, do_continuous=True),\n",
    "        val_samples=val_size-val_size%batch_size, )\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "lmdbval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Saving file: Sampling_Training_Instances.ipynb

===========
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Data Preparation\n",
    "\n",
    "\n",
    "This python notebook deals with finding suitable training instances (around ROI fiber borders).\n",
    "\n",
    "This procedure relies on [ImageJ](https://imagej.net/Welcome) functions (specifically **threshold** and **analyze particles**), to create the ROI border image masks (saved using the **Draw** command).\n",
    "\n",
    "Specifically 2 ROI border masks were used:\n",
    "1. Big ROI cells - larger sampling window;\n",
    "2. Small ROI cells - smaller sampling window.\n",
    "\n",
    "\n",
    "The output of this processing step is a set of sampling image masks -- in which every **non-black** pixel represents a selected training instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-vsIXRauZCw"
   },
   "source": [
    "## Importing Modules\n",
    "\n",
    "Here we import the needed python functions for sampling ROIs.\n",
    "\n",
    "+ The main data processing is done using the [Numpy](http://www.numpy.org/) Scientific Computing Framework.\n",
    "\n",
    "Also the Whole Package Help is displayed, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m6Uk4Dy1uZCx",
    "outputId": "5e9889d3-0845-42df-8619-7f3b7fdaa8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package dnn_segmentation:\n",
      "\n",
      "NAME\n",
      "    dnn_segmentation - # FrontalLobe_DNN_Seg\n",
      "\n",
      "DESCRIPTION\n",
      "    Main package for DNN Segmentation on Neuron Fibers.\n",
      "    \n",
      "    Containing 3 main modules\n",
      "    \n",
      "    1. Data Preparation\n",
      "       + Choosing Sampling Instances\n",
      "       + Saving Training Instances in a lmdb base, for convinience.\n",
      "    2. Neural Networks Processing\n",
      "       + Pretraining Module (Autoencoder or Convolutional RBM network) \n",
      "       + Deep Neural Network (Using to DNN correct pre-processed images.)\n",
      "    3. Ray Measuring Neuron fiber ROIs\n",
      "       + Ray Measuring ROIs\n",
      "       + Matching ROIs between two sets (Annotation, DNN Corrected)\n",
      "       + Discarding some DNN Damaged ROIs\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    data_prep (package)\n",
      "    net (package)\n",
      "    raym (package)\n",
      "\n",
      "FILE\n",
      "    /media/kiks/My_Files/working/dnn_seg/main_repo/dnn_segmentation/__init__.py\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every import is succesful !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "print(help(\"dnn_segmentation\"))\n",
    "\n",
    "from dnn_segmentation.data_prep.utils.sample_set_funcs import get_good_patches,ConfigSample\n",
    "from dnn_segmentation.net.utils.train_h import save_relevant\n",
    "\n",
    "print('Every import is succesful !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66f0UJc8uZC4"
   },
   "source": [
    "\n",
    "## Experiment Basic Setup\n",
    "\n",
    "+ Code to set the random seed\n",
    "+ Save the current processing configuration (all conf files in current dir.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "B5QWPv6luZC5"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(8)\n",
    "#np.random.seed(None)\n",
    "\n",
    "\n",
    "#  Sampling Experiment ID\n",
    "experiment_id='sample_'+''.join(map(chr,np.random.randint(97,97+26,(5,))) )\n",
    "\n",
    "conf_test_tosave=save_relevant('saved_confs',experiment_id,\n",
    "            files=[ f for f in os.listdir('.') \n",
    "                   if os.path.isfile(f) and not f.endswith('.pyc')],\n",
    "            just_return=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDqGkJyxuZC9"
   },
   "source": [
    "\n",
    "# EXPERIMENT SETUP PARAMETERS\n",
    "\n",
    "Setting the actual sampling specific parameters:\n",
    "\n",
    "1. Description Text;\n",
    "2. Lookup Paths;\n",
    "\n",
    "\n",
    "3. ROI Sampling Parameters;\n",
    "4. Noise (Uniform) Sampling Parameters;\n",
    "5. ROI Noise Sampling Parameters, not used currently\n",
    "\n",
    "\n",
    "6. Training image shortcodes, (sampling is usually applied on 20 images, train subselection)\n",
    "\n",
    "The testing sampling was uniformly distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T1I1XGI0uZC9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tagging/Saving current configuration\n",
    "DESCRIPTION_TEXT='sample ONSET, onspecific settings'\n",
    "save_conf=True\n",
    "\n",
    "\n",
    "# lookup paths params-------\n",
    "lookup_path= {}\n",
    "lookup_path['groundtruth'] = r'/media/kiks/My_Files/working/dnn_seg/test/Consensus corrected'\n",
    "lookup_path['interim'] = r'/media/kiks/My_Files/working/dnn_seg/test/interim_used'\n",
    "lookup_path['bigc'] = r'/media/kiks/My_Files/working/dnn_seg/test/sample_bigcells'\n",
    "lookup_path['smallc'] = r'/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells'\n",
    "lookup_path['debri'] = '###################'\n",
    "conf=ConfigSample()\n",
    "\n",
    "# general sample params---\n",
    "conf.save_loc = r'/media/kiks/My_Files/working/dnn_seg/test/save_train_instances'\n",
    "conf.img_size=2400\n",
    "conf.win_offs_big = 35\n",
    "conf.win_sparsity_big = 0.12\n",
    "conf.win_offs_small = 5\n",
    "conf.win_sparsity_small = 0.15\n",
    "\n",
    "# noise unif params-------\n",
    "conf.win_offs_noise = 5\n",
    "conf.win_sparsity_noise = 0.15\n",
    "conf.noise_big_sparsity = 0.85\n",
    "conf.noise_val = 255\n",
    "\n",
    "# noise roi not used for now-----------------\n",
    "conf.dbscan_eps = 10\n",
    "conf.dbscan_mins = 20\n",
    "conf.win_offs = 22\n",
    "conf.win_noiseroi_spar = 0.08\n",
    "\n",
    "# pixel in interims-------------\n",
    "leave_pix_noise = 0.1\n",
    "pix_remove_thres = 50\n",
    "\n",
    "\n",
    "# sampling images params----\n",
    "train_images=['sp14484-img04', 'sp14485-img05', 'sp13909-img05', 'sp14240-img03', 'sp14069-img04',\n",
    " 'sp14250-img03', 'sp13750-img09', 'sp13750-img03', 'sp13880-img07',\n",
    " 'sp14069-img01', 'sp13909-img11', 'sp13909-img07', 'sp14370-img10',\n",
    " 'sp14240-img01', 'sp14245-img04', 'sp13726-img08', 'sp13880-img11',\n",
    " 'sp14485-img03', 'sp14485-img09', 'sp14370-img07']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFHW7ooGuZDA"
   },
   "source": [
    "## RUNNING THE SETUP CONFIGURATION\n",
    "\n",
    "1. Iterating all above images\n",
    "   * Creating an empty image mask;\n",
    "   * Iterating every ROI border point; \n",
    "   * Randomly choosing/drawing sample pixels (using a sample window centered at the border point;\n",
    "   * Saving the obtained mask file.\n",
    "   \n",
    "2. Saving the experiment configuration files (current code folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "345r2H4ruZDB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groundtruth image set- has 30 images\n",
      "interim image set- has 30 images\n",
      "bigc image set- has 19 images\n",
      "smallc image set- has 19 images\n",
      "img is:  0 51402 0.008923958333333334\n",
      "/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells/mask_sp13726-img08-interim.tif\n",
      "img is:  1 75667 0.013136631944444444\n",
      "/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells/mask_sp13909-img05-interim.tif\n",
      "img is:  2 76336 0.013252777777777778\n",
      "/media/kiks/My_Files/working/dnn_seg/test/sample_smallcells/mask_sp13909-img07-interim.tif\n",
      "len good_patches:  126008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(conf.save_loc):\n",
    "    os.makedirs(conf.save_loc)\n",
    "\n",
    "\n",
    "\n",
    "test_images = {}\n",
    "for pic_type in 'groundtruth;interim;bigc;smallc'.split(';'):\n",
    "    print ('{} image set- has {} images'.format(pic_type,\n",
    "                        len(glob.glob(os.path.join(lookup_path[pic_type], '*.tif'))) ) )\n",
    "    \n",
    "    \n",
    "    test_images[pic_type] = [filename for ind, filename in\n",
    "                             enumerate(glob.glob(os.path.join(lookup_path[pic_type], \n",
    "                                                              '*.tif')))\n",
    "         if filename[filename.rindex('sp'):filename.rindex('img') + 5] \\\n",
    "         in train_images]\n",
    "    test_images[pic_type].sort(key=lambda name: name[name.rindex('sp'):])\n",
    "\n",
    "\n",
    "print( len(test_images['groundtruth']), test_images['groundtruth'],\n",
    "\n",
    "get_good_patches(test_images, conf.save_loc, conf.win_offs,conf) )\n",
    "\n",
    "\n",
    "if save_conf:\n",
    "    save_relevant('saved_confs',experiment_id,\n",
    "                  str_to_save=conf_test_tosave,descriptive_text=DESCRIPTION_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "De2WL1-RuZDD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Sampling Training Instances.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

Saving file: JythonTest.ipynb

===========
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dir(java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from java.util import ArrayList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ArrayList()\n",
    "a.add(\"1\")\n",
    "a.add(\"2\")\n",
    "a.add(\"3\")\n",
    "print(\"As easy as \"+' '.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jython",
   "language": "python",
   "name": "jython_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "text/x-python",
    "version": 2
   },
   "file_extension": ".py",
   "help_links": [
    {
     "text": "Jython",
     "url": "www.jython.org"
    },
    {
     "text": "Jython Kernel Help",
     "url": "https://github.com/suvarchal/IJython"
    }
   ],
   "mimetype": "text/x-python",
   "name": "jython",
   "pygments_lexer": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

Saving file: Creating Neural Net Visualisations.ipynb

===========
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import os,sys,glob\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.models import Model,load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import dnn_segmentation.net.utils as net_utils\n",
    "\n",
    "from dnn_segmentation.data_prep.utils.patcher import image_iterator_new\n",
    "from dnn_segmentation.net.utils.train_h import make_intmodel, draw_someoutput, \\\n",
    "    draw_one, make_split_map,pad_one_makesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(subsample_mask):\n",
    "    filenames, test_path, type_set, patches_count, save_path = (\n",
    "    test_image_paths, lookup_test_path, \"all_test\", 0, '#####')\n",
    "\n",
    "    lenF = len(filenames)\n",
    "    for find, filename in enumerate(filenames):\n",
    "        print('Running on img:{}'.format(filename[filename.rindex(os.path.sep) + 1:]))\n",
    "        sys.stdout.flush()\n",
    "        patches = image_iterator_kiko(filename, test_path, groundtruth_path,\n",
    "                                      type_set, patches_count, save_path, do_expand=True, patch_size=patch_size,\n",
    "                                      subsample_patch_mask=subsample_mask)\n",
    "        return patches\n",
    "\n",
    "def transform_patch(x):\n",
    "    xback, xax, xmil = np.zeros((3,) + x.shape, dtype=x.dtype)\n",
    "    xback[(x == 255) | (x == 3)] = 1\n",
    "    xax[(x == 128) | (x == 2)] = 1\n",
    "    xmil[(x == 0) | (x == 1)] = 1\n",
    "    x_patch = np.concatenate((xmil, xax, xback), axis=-1)\n",
    "    new_x=np.pad(  x_patch, ((1,2),(1,2)),'constant',constant_values=0 )\n",
    "\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_model_loc = r'D:\\code_projects\\Neuron_fibers_workspace\\models\\replication\\weights_quickbig_wdog.00-0.8876.hdf5'\n",
    "\n",
    "save_picdir=r'D:\\code_projects\\Neuron_fibers_workspace\\neuron_fiber_images\\layers_output\\zulhtheq'\n",
    "\n",
    "\n",
    "lookup_test_path = \"D:/code_projects/Neuron_fibers_workspace/neuron_fiber_images/test_spread_interim/\"\n",
    "groundtruth_path = \"D:/code_projects/Neuron_fibers_workspace/neuron_fiber_images/all_test_big_corrected/\"\n",
    "patch_size=45\n",
    "\n",
    "\n",
    "test_image_paths=[filename for ind,filename in enumerate(glob.glob(os.path.join(lookup_test_path, '*.tiff')) ) \\\n",
    "if  filename[filename.rindex(os.path.sep)+1:filename.rindex('img')+5] ]\n",
    "\n",
    "\n",
    "baseline= load_model(save_model_loc, custom_objects={'AutoEncoderLayer': \\\n",
    "                                                     net_utils.AutoEncoderLayer.AutoEncoderLayer})\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ------------------------------------------------------------\n",
    "# ------------------------------------------------------------\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "int_models={}\n",
    "\n",
    "for lay in baseline.layers[0:]:\n",
    "    pass\n",
    "    lay_name=lay.get_config()['name']\n",
    "    \n",
    "    \n",
    "    # POSSIBLE LAYERS TO VISUALISE\n",
    "    # if lay_name.startswith('maxpooling2d_1') or lay_name.startswith('maxpooling2d_2') \\\n",
    "    # or lay_name.startswith('maxpooling2d_3'):  #lay_name.startswith('maxpooling2d_3') or \\\n",
    "    #    lay_name.startswith('maxpooling2d_5'):\n",
    "    \n",
    "    if lay_name.startswith('upsampling'):\n",
    "        int_models[lay_name]=make_intmodel(baseline,lay,lay_name)\n",
    "        print(lay_name,lay.get_output_shape_at(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "subsample_mask=np.zeros((2048,2048),dtype=bool)\n",
    "# which_pix=\\\n",
    "# '''609,618\n",
    "# 608,1628\n",
    "# 614,1618\n",
    "# 626,1617\n",
    "# 625,1617'''.splitlines()\n",
    "\n",
    "which_pix=\\\n",
    "'''654,1274\n",
    "653,1272\n",
    "659,1264\n",
    "660,1266\n",
    "671,1355\n",
    "671,1349\n",
    "681,1345\n",
    "681,1357\n",
    "681,1341\n",
    "666,183\n",
    "670,188\n",
    "673,189\n",
    "696,136\n",
    "705,107\n",
    "'''.splitlines()\n",
    "\n",
    "which_pix=np.array([tuple(map(int,cor.split(','))) for cor in which_pix])[:3]\n",
    "\n",
    "# subsample_mask[which_pix[:,1],which_pix[:,0]]=True\n",
    "\n",
    "subsample_mask[(np.random.rand(2048,2048)<0.2)]=True\n",
    "\n",
    "subsample_mask=subsample_mask.flatten()\n",
    "\n",
    "save_out={}\n",
    "save_out['maxpooling2d_1']=np.zeros((80,24,24))\n",
    "save_out['maxpooling2d_2']=np.zeros((70,12,12))\n",
    "save_out['maxpooling2d_3']=np.zeros((60,6,6))\n",
    "\n",
    "save_out['maxpooling2d_1_in']=np.zeros((80,45,45))\n",
    "save_out['maxpooling2d_2_in']=np.zeros((70,45,45))\n",
    "save_out['maxpooling2d_3_in']=np.zeros((60,45,45))\n",
    "\n",
    "\n",
    "for pic_ind,picture in enumerate(get_patches(subsample_mask)):\n",
    "    if picture[0] is None:\n",
    "        continue\n",
    "\n",
    "    if pic_ind%500==0: print ('making sample for: ',pic_ind)\n",
    "    rowx,coly=picture[-1]\n",
    "    #draw_one(picture[0],'pic_({},{})'.format(coly,rowx))\n",
    "    #draw_one(picture[0][21:-21,21:-21], 'pic_({},{})_small{}'.format(coly, rowx,picture[1] ))\n",
    "\n",
    "    patch_proc=make_split_map(picture[0],dopad=True)\n",
    "    for inm in sorted(int_models.keys()):\n",
    "\n",
    "        output=int_models[inm]([patch_proc ,0])[0]\n",
    "        out_shape=output.shape\n",
    "        output=output.transpose(3,1,2,0).reshape(out_shape[-1],out_shape[1],out_shape[2])\n",
    "        out_inds=np.arange(output.shape[0],dtype=int).reshape(-1,1)\n",
    "        # print(inm)\n",
    "\n",
    "        if  'crbm' in inm or 'activ' in inm:\n",
    "            print('im really here')\n",
    "\n",
    "        # np.random.shuffle(out_inds)\n",
    "\n",
    "        sum_act=np.sum(output.reshape(-1,out_shape[1]*out_shape[2]),axis=1).reshape(-1,1)\n",
    "        sum_inds=np.hstack((sum_act,out_inds))\n",
    "\n",
    "        sum_sact=np.sum(save_out[inm].reshape(-1,save_out[inm].shape[1]*save_out[inm].shape[2]),axis=1).reshape(-1,1)\n",
    "        which_big=(sum_act>sum_sact).flatten()\n",
    "        save_out[inm][which_big]=output[which_big]\n",
    "        save_out[inm+\"_in\"][which_big]=np.broadcast_to(picture[0],(np.sum(which_big),)+picture[0].shape)\n",
    "        pass\n",
    "        # sum_act=list(sum_inds)\n",
    "        # sum_act.sort(key=lambda x: -x[0])\n",
    "        # sum_act=np.array(sum_act)\n",
    "\n",
    "        # draw_someoutput(output[sum_act[:81,1].astype(int) ],join(save_picdir,'pic_({},{})_{}'.format(coly,rowx,inm)))\n",
    "        # patch_proc=output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# draw_someoutput( save_out['maxpooling2d_1'],save_picdir,draw_suffix='pic_layer_1'.format())\n",
    "# draw_someoutput( save_out['maxpooling2d_1_in'],save_picdir,chosen_cmap='gray',\n",
    "#                  draw_suffix='pic_layer_1_in'.format())\n",
    "# draw_someoutput(save_out['maxpooling2d_2'],save_picdir,draw_suffix='pic_layer_2'.format())\n",
    "# draw_someoutput(save_out['maxpooling2d_2_in'],save_picdir,chosen_cmap='gray'\n",
    "#                 ,draw_suffix='pic_layer_2_in'.format())\n",
    "#\n",
    "# draw_someoutput(save_out['maxpooling2d_3'],save_picdir,draw_suffix='pic_layer_3'.format())\n",
    "# draw_someoutput(save_out['maxpooling2d_3_in'],save_picdir,chosen_cmap='gray'\n",
    "#                 ,draw_suffix='pic_layer_3_in'.format())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Saving file: Sampling ROI Borders (ImageJ).ipynb

===========
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../depends/ij.jar')\n",
    "\n",
    "from ij import IJ \n",
    "from ij.io import FileSaver \n",
    "import os \n",
    "from ij.plugin.frame import RoiManager\n",
    "from ij.gui import Roi\n",
    "from ij.measure import ResultsTable\n",
    "from ij.plugin.filter import ParticleAnalyzer\n",
    "from ij.plugin.filter.ParticleAnalyzer import ADD_TO_MANAGER,EXCLUDE_EDGE_PARTICLES\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jython",
   "language": "python",
   "name": "jython_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

Saving file: Saving Instances to Database.ipynb

===========
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import dnn_segmentation\n",
    "\n",
    "#SETUPP    ============================\n",
    "from  dnn_segmentation.data_prep.utils.create_lmdb_batch_funcs import   \\\n",
    "        reduce_files,make_db_folder,create_lmdbs\n",
    "\n",
    "from  dnn_segmentation.data_prep.utils.data_helper import create_chessmask\n",
    "\n",
    "from dnn_segmentation.net.utils.models import get_2k_image_2layer_convnetmodel\n",
    "from dnn_segmentation.net.utils.train_h import save_relevant\n",
    "\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!!!!!!!!!!!!NOT NEEDED ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "image_list_folder='#########'\n",
    "image_prepend='###########'\n",
    "save_path = '#################'\n",
    "patch_dir='##################'\n",
    "save_path = '#################'\n",
    "# =============================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(None)\n",
    "quick_str='base_'+''.join(map(chr,np.random.randint(97,97+26,(5,))) )\n",
    "files_save=[ os.path.join('data_funcs',f) for f in os.listdir('data_funcs') \\\n",
    "             if os.path.isfile(os.path.join('data_funcs',f))\n",
    "             and not os.path.join('data_funcs',f).endswith('.pyc')]\n",
    "files_save.insert(0,os.path.basename(__file__))\n",
    "\n",
    "conf_test_tosave=save_relevant('data_funcs/saved_baseconfs',quick_str,\n",
    "            files=files_save,\n",
    "            just_return=True)\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DESCRIPTION_TEXT='normal sample, interim ON, 8 mil, specific images and sampling, 61window 3x3 grid'\n",
    "\n",
    "db_folder=r'D:\\data_projects\\neuron_fibers_data\\BASES\\8mil_61_bigp_Wsize_20imgs_interimONset'\n",
    "\n",
    "save_base=True\n",
    "image_width,image_height=61,61\n",
    "big_image_size=2400\n",
    "lookup_path = r'D:\\data_projects\\neuron_fibers_data\\images\\ML_SET_ON01\\cints_new_general'\n",
    "\n",
    "groundtruth_path = r'D:\\data_projects\\neuron_fibers_data\\images\\cors\\c'\n",
    "\n",
    "\n",
    "\n",
    "val_images='sp14252-img06,sp14436-img05,sp14436-img04,sp14252-img08'.split(',')\n",
    "\n",
    "# Interim mlset02\n",
    "val_images='sp13878-img05,sp13933-img02,sp14105-img03,sp14436-img03'.split(',')\n",
    "\n",
    "#interim rand\n",
    "# val_images=['sp13909-img05', 'sp14252-img01', 'sp13878-img05', 'sp13938-img01', 'sp14252-img07']\n",
    "\n",
    "# mlset ON\n",
    "val_images=['sp13726-img09', 'sp14245-img06', 'sp14484-img01', 'sp13750-img01']\n",
    "\n",
    "\n",
    "test_image_val=[filename for ind,filename in enumerate(glob.glob(os.path.join(lookup_path, '*.tif')) ) \\\n",
    "if  filename[filename.rindex(os.path.sep)+1:filename.rindex('img')+5] in val_images ]\n",
    "\n",
    "val_do_expand=False\n",
    "percent_patches_used_val=np.array([1,1,1])*0.1  #np.array([0.837,0.744,1])*0.1 #[4.0/19,7.0/10,1]\n",
    "phase_done_val='val'\n",
    "val_batch_size=1*10**5\n",
    "val_lmdb_GBsize=80\n",
    "\n",
    "\n",
    "\n",
    "train_mask_dir=r'D:\\data_projects\\neuron_fibers_data\\images\\patch_mask_ON_chosenTrainingImgs\\\\'\n",
    "\n",
    "contested_img='sp13726-img07'\n",
    "train_images='sp14436-img08,sp13909-img01,sp13909-img02,sp13938-img07,sp13726-img01,sp14252-img05,sp13909-img07,sp13909-img08,sp13909-img03,sp13933-img04,sp13726-img04,sp13726-img03,sp13933-img08,sp13909-img05,sp13726-img02,sp13933-img05,sp13933-img06,sp13933-img07,sp13909-img06,sp13726-img08'.split(',')\n",
    "\n",
    "\n",
    "\n",
    "#Interim mlse02 train\n",
    "train_images=('sp13938-img01,sp13750-img08,sp14252-img02,sp14105-img08,sp13750-img04,sp14105-img04,'+\n",
    "'sp14105-img07,sp13938-img02,sp13878-img06,sp13938-img03,sp14252-img01,sp13750-img03,'+\n",
    "'sp13750-img07,sp14436-img01,sp13750-img02,sp13933-img03,sp14105-img06,sp14105-img02,'+\n",
    "'sp13750-img01,sp14436-img02').split(',')\n",
    "\n",
    "\n",
    "#Interim ONSET\n",
    "train_images=['sp14484-img04', 'sp14485-img05', 'sp13909-img05', 'sp14240-img03', 'sp14069-img04',\n",
    " 'sp14250-img03', 'sp13750-img09', 'sp13750-img03', 'sp13880-img07',\n",
    " 'sp14069-img01', 'sp13909-img11', 'sp13909-img07', 'sp14370-img10',\n",
    " 'sp14240-img01', 'sp14245-img04', 'sp13726-img08', 'sp13880-img11',\n",
    " 'sp14485-img03', 'sp14485-img09', 'sp14370-img07']\n",
    "\n",
    "\n",
    "\n",
    "# RANDSET+++++++++++++++++++\n",
    "# train_images=('sp14436-img04,sp13909-img03,sp14436-img06,'+\n",
    "# 'sp13726-img05,sp13909-img06,sp14436-img07,sp14105-img02,'+\n",
    "# 'sp13750-img04,sp13909-img07,sp13750-img01,sp13909-img01,'+\n",
    "# 'sp14252-img03,sp13933-img05,sp13726-img08,sp13750-img07,'+\n",
    "# 'sp14105-img07,sp13933-img04,sp14436-img02,sp13938-img02,sp14436-img03').split(',')\n",
    "\n",
    "\n",
    "\n",
    "test_image_train=[filename for ind,filename in enumerate(glob.glob(os.path.join(lookup_path, '*.tif')) )\\\n",
    "\n",
    " if  filename[filename.rindex(os.path.sep)+1:filename.rindex('img')+5] in train_images ]\n",
    "\n",
    "train_do_expand=False\n",
    "percent_patches_used_train= np.array([1,1,1])*0.65#*(1.0/8)  #[4.0/19,7.0/10,1]\n",
    "phase_done_train='train'\n",
    "\n",
    "train_batch_size=1*10**5\n",
    "train_lmdb_GBsize=350\n",
    "\n",
    "do_special={'perc_switch':0,'not_mix_patches':True,\n",
    "            'two_patch':True,'folded_expand':True}\n",
    "# do_special=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "start_time = time.time()\n",
    "print ('Creating images at \"%s\" ...' % db_folder)\n",
    "print( 'Working on: ',len(test_image_val),test_image_val)\n",
    "\n",
    "make_db_folder(db_folder)\n",
    "\n",
    "create_lmdbs(db_folder,    phase_done_val,    (test_image_val,lookup_path, groundtruth_path, \"all_test\", 0, save_path),image_list_folder,image_prepend,image_width,image_height,smaller_size=percent_patches_used_val,random_key_prepend=12,do_expand=val_do_expand,patch_size=image_width,save_base=save_base,batch_size=val_batch_size,base_GBsize=val_lmdb_GBsize,\n",
    "            do_special=do_special\n",
    "            )\n",
    "reduce_files(db_folder,phase_done_val)\n",
    "\n",
    "print( 'Done after {:.2f} hours'.format((time.time() - start_time)/3600 ))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print ('Working on: ',len(test_image_train),test_image_train)\n",
    "\n",
    "create_lmdbs(db_folder,    phase_done_train,    (test_image_train,lookup_path, groundtruth_path, \"all_test\", 0, save_path),image_list_folder,image_prepend,image_width,image_height,smaller_size=percent_patches_used_train,mean_name='mean.jpg',random_key_prepend=12,do_expand=train_do_expand,patch_size=image_width,save_base=save_base,batch_size=train_batch_size,mask_dir=train_mask_dir,base_GBsize=train_lmdb_GBsize,\n",
    "           do_special=do_special\n",
    "            )\n",
    "reduce_files(db_folder,phase_done_train)\n",
    "\n",
    "print( 'Done after {:.2f} hours'.format((time.time() - start_time)/3600 ))\n",
    "\n",
    "# ====================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "save_relevant('data_funcs/saved_baseconfs',quick_str,str_to_save=conf_test_tosave,descriptive_text=DESCRIPTION_TEXT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

